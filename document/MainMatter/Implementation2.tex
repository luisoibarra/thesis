\chapter{Detalles de Implementación y Experimentos}\label{chapter:implementation}

% Explicación de las métricas: F1, %F1, Precision, Recobrado
% Con que software se hizo el modelo: Keras, Tensorflow
% Explicacion de corpus estudiados: Decir que los esquemas de argumentacion presentes son diferentes, por lo tanto
% usaron varios para ver cual era el mejor que se acomodaba al conjunto de validación final (Granma)
% Experimentación con segmenter
% Experimentación con link prediction
% Conclusiones: Mejor clasificar y segmentar UDA con segmenter y dejar la clasificacion de UDA como tarea auxiliar en 
% link prediction, poner los mejores ejemplos y peores ejemplos para los mejores modelos.

\section{Conjuntos de Datos}

Para el entrenamiento de los modelos propuestos se utilizaron corpus diferentes, estos
presentas esquemas de anotaci'on distintos entre s'i. Dado que todos los corpus estaban en ingl'es, 
se les aplic'o previamente el algoritmo de proyecci'on de corpus propuesto y se crearon sus respectivas
versiones en espannol. A los conjuntos de entrenamientos se le aplic'o la t'ecnica de \emph{backtranslation}
para aumentar su tamaño. Como conjunto de validación fueron usados cartas extra'idas del peri'odico Granma.

\subsection{Ensayos Argumentativos}\label{corpus:persuasive_essays}

Este corpus [TODO \cite{CORPUS PAPER}] presenta unos 402 documentos, dividido por los autores en 286 documentos para entrenamiento (70\%), 
80 para prueba (20\%) y 36 para validación (10\%). Los contenidos de estos son ensayos de estudiantes sobre temas
como por ejemplo: cooperar o competir, contribuciones de la tecnolog'ia a la sociedad.
Las anotaciones de las UDA se conforman por segmentos 
de textos considerados argumentativos, estos segmentos son clasificados en MajorClaim (751), Claim (1506) y Premise (3832).
La estructura de las relaciones entre las UDA conforman 'arboles en los que se tienen como ra'iz las 
MajorClaim del texto. Las relaciones solo estan permitidas entre Premise-Premise y Premise-Claim, clasificadas
en de ataque (219) o apoyo (3613). Las relaciones entre Claim y MajorClaim son anotadas de manera diferente, por medio de 
darle a las Claim una clasificaci'on de si est'a a favor (1228) o en contra (278) de las MajorClaim del documento.
Para el an'alisis de este corpus se consideraron las relaciones Claim-MajorClaim de igual manera que las otras.

\subsection{CDCP}\label{corpus:cdcp}

TODO PONERLE NUMEROS A LOS PORCIENTOS

El corpus [TODO \cite{CORPUS PAPER}] est'a conformado por 731 comentarios de usuarios extra'idos de la web bajo el tema de 
pr'acticas de cobro de deudas a los consumidores (CDCP por sus siglas en ingles Consumer Debt Collection Practices).
Las UDA se encuentran segmentadas en oraciones y todas se consideran argumentativas, estas son clasificadas en 
POLICY (17\%), VALUE (45\%), FACT (16\%), TESTIMONY (21\%) y REFERENCE (1\%). Las relaciones se encuentran 
clasificadas en REASON (97\%) y EVIDENCE (3\%), aunque los datos presenta una baja conexión entre ellos, con 
aproximadamente el 3\% de los posibles pares anotados.

\subsection{AbsTRCT}

TODO 

\subsection{Aumento de Datos}

\emph{Backtranslation} se aplic'o a los textos originales en ingl'es, como lenguaje intermedio se utiliz'o el espannol.
Una vez se ten'ia la traducción se utiliz'o el algoritmo de proyección de etiquetas para el anotado de las etiquetas sobre
las versiones nuevas.
Al aplicar \emph{backtranslation} sobre los conjuntos de datos su tamanno se duplic'o aunque los textos se mantuvieron
similares. 

TODO M'etricas de comparaci'on entre los textos traducidos y los originales.

\subsection{Cartas a la direcci'on}

Las cartas a la direcci'on constituyen un segmento del peri'odico Granma en los cuales son publicadas
cartas enviadas por la poblaci'on o empresas a dicha entidad. En general, las cartas 
presentan dudas o problemas de la poblaci'on con el objetivo de obtener respuestas del organismo
asociado. Se extrajeron 2891 cartas desde el 30 de agosto del 2013 hasta el 28 de octubre del 2022. Se 
presentan aproximadamente 975000 palabras en los datos, en promedio, la cantidad de palabras por carta es de 330.
Se encontraron 874 cartas en respuesta a cartas enviadas lo que representa un 30\% del total. Se extrajeron
los comentarios asociados a las cartas, en este sentido 987 cartas no presentan comentarios y en promedio 
se realizan 2 comentarios por carta. Los textos presentan un t'itulo y un formato relativamente libre, 
aunque en las cartas de respuesta se puede observar una firma de la persona que respondi'o y la entidad que 
representa.

TODO SI HAY TIEMPO ANOTAR LAS CARTAS CON ALGUN ESQUEMA SENCILLO (Claim, Premise) (Attack, Support) y Mapear 
las clasificaciones de los otros modelos a estas para tener algun tipo de evaluacion.

\section{Experimentación}

Para realizar la selecci'on del modelo se utiliz'o el corpus de Ensayos Argumentativos. Con este se ajustaron
las arquitecturas e hiperpar'ametros de los modelos propuestos. La mejor combinaci'on de estos fue utilizada para el entrenamiento de
los corpus restantes. Finalmente los modelos fueron utilizados para anotar las cartas a la direcci'on. 

\subsection{Software y Hardware}

El lenguaje empleado para la confecci'on del software fue \textbf{Python}, este presenta una gran variedad de herramientas 
para el trabajo con texto, visualizaci'on de datos y la creaci'on de modelos de aprendizaje profundo.
Se utiliz'o \textbf{tensorflow} en su versión 2.9.2 para la construcci'on y entrenamiento de los modelos. 
Para el procesamiento de los textos se utilizaron \textbf{nltk} y \textbf{spacy}, con estos se realizaron tareas
como la extracción de tokens y oraciones del texto, la anotaci'on de las etiquetas \textbf{POS}. Se utilizaron 
ambas bibliotecas para el procesamiento debido que en dependencia de la sitaución cada una presenta diferentes
ventajas. En el caso de \textbf{nltk} esta presenta algoritmos r'apidos para el procesamiento de texto que no 
requieren de muchos recursos computacionales, sin embargo, estos algoritmos no est'an disponibles de inmediato
para otros lenguajes como el espannol. \textbf{Spacy} por su parte presenta algoritmos m'as certeros a costo 
de mayor tiempo de procesamiento y gasto de recursos computacionales y también presenta una cantidad de lenguajes 
disponibles mucho mayor. Para la visualizaci'on, manejo de los datos y c'alculo de m'etricas se utilizaron 
\textbf{matplotlib}, \textbf{pandas} y \textbf{sklearn}.

Gran parte del procesamiento se llevo a cabo en una computadora $i5$ con $8GB$ de RAM ampliada con $4GB$ de memoria 
swap [TODO \cite{Memoria swap}], aunque se requiri'o el uso de la plataforma \textbf{Colab} [TODO \cite COLAB] para 
el entrenamiento de algunos modelos por falta de recuros locales.

\subsection{Segmentador de UDA}

Para el segmentador se probaron variantes de la arquitectura asignando valores de hiperpar'ametros a los propuestos
por las investigaciones originales. (TODO Poner las asignaciones de hiperparametros que no var'ian). Las variaciones 
de la arquitectura se vieron dadas por la presencia o no de lo siguientes elementos:

\begin{itemize}
    \item Atributos de POS en la entrada del algoritmo
    \item Atributos extra'idos por la CNN de la palabra.
    \item Atributos features extra'idos por la LSTM bidireccional de la palabra.
    \item Conexiones residuales
    \item Capa densa final
    \item Capas de normalizaciones
\end{itemize}

Los resultados obtenidos son:

TODO FOTOS o TABLAS con los resultados relevantes en Persuassive Essays

Se eligi'o el modelo con (TODO poner el modelo escogido) debido a los resultados presentados.

TODO FOTOS o TABLAS con los resultados relevantes en los OTROS CORPUS

TODO Mostrar ejemplos buenos y malos
TODO Decir opiniones de los errores
TODO Hacer analisis curvas de aprendizaje -> overfitting, underfitting, representaci'on de los datos en los conjuntos de validacion/entrenamiento

\subsection{Predictor de Enlaces}

Se entrenaron diferentes variantes de arquitecturas con diferentes hiperpar'ametros. Los hiperpar'ametros
iniciales fueron los propuestos por la investigaci'on original y tambi'en fueron probados algunas variantes 
de estos. La arquitectura var'ia por la presencia del m'odulo de atención en esta.

Se construyeron varios conjuntos de hiperpar'ametros. Los resultados fueron:

TODO PONER TABLA con los conjuntos de los hiperpar'ametros

TODO FOTOS o TABLAS con los resultados relevantes en Persuassive Essays 

El modelo elegido fue (TODO poner el modelo escogido).

TODO FOTOS o TABLAS con los resultados relevantes en los OTROS CORPUS

TODO Mostrar ejemplos buenos y malos
TODO Decir opiniones de los errores
TODO Hacer analisis curvas de aprendizaje -> overfitting, underfitting, representaci'on de los datos en los conjuntos de validacion/entrenamiento

\subsection{Modelo conjunto}

Dado que la clasificación de UDAs es hecha tanto en el segmentador como en el predictor de enlaces es necesaria 
la selecci'on de c'omo se va a desambiguar esta clasificaci'on. En base a los resultados obtenidos en el proceso
de experimentaci'on se prefiri'o el resultado devuelto por el segmentador de UDAs.

TODO Poner estadisticas de ambas aproximaciones

\section{Validaci'on}

Se entrenaron varios modelos en los diferentes corpus con los hiperpar'ametros seleccionados. Con estos modelos 
se procesaron las cartas y se observ'o cual era el que m'as se ajustaba a las estructuras argumentativas presentes 
en estas. Dado que la definición de UDA es algo que var'ia, es complejo realizar un m'etodo que eval'ue de forma 
justa los resultados obtenidos por los diferentes modelos de manera conjunta. TODO

\subsection{Ensayos Argumentativos}

TODO Resultados obtenidos en el Granma con el modelo.
TODO Mostrar ejemplos buenos y malos

\subsection{CDCP}

TODO Resultados obtenidos en el Granma con el modelo.
TODO Mostrar ejemplos buenos y malos

\subsection{AbsTRCT}

TODO Resultados obtenidos en el Granma con el modelo.
TODO Mostrar ejemplos buenos y malos

\subsection{Consideraciones}

TODO Poner cual modelo se considera mejor para el Granma 
TODO Decir opiniones de los errores. (El texto de Granma posee una estructura diferente al entrenante)
