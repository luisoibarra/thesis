\documentclass[a4paper,11pt,twocolumn,twoside]{article}
\usepackage[dvips]{graphicx}
\usepackage{sepln}
\usepackage{changepage}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{svg}
\usepackage{url}
\usepackage{fullname_esp}
\usepackage[utf8]{inputenc}
\usepackage[spanish,es-nosectiondot, es-tabla, es-noindentfirst, es-nolists]{babel}

\input epsf

\setlength\titlebox{4in} %esto por defecto

\title{Extracción automática de estructuras argumentativas en textos de opinión cubanos mediante proyección de etiquetas y aprendizaje profundo}

\author {\textbf{Luis Ernesto Ibarra Vázquez,$^1$} \textbf{Damian Valdés Santiago$^1$}\\
$^1$Facultad de Matemática y Computación, Universidad de La Habana, Cuba\\
% $^2$Universidad de la Habana\\
luise98cu@gmail.com, dvs89cs@matcom.uh.cu\\
}

\seplntranstitle{Automatic extraction of argumentative structures in Cuban opinion texts through label projection and deep learning}

\seplnclave{Extracción de argumentos, procesamiento de lenguaje natural, aprendizaje profundo.} % TODO Seguir en esto

\seplnresumen{
La Extracción de Argumentos se realiza tradicionalmente mediante anotación
manual de expertos en lingüística, lo que demora mucho tiempo. 
Este artículo propone aplicar algoritmos de aprendizaje profundo 
al campo de la Extracción de Argumentos en textos de la prensa cubana, constituyendo el 
primero de su tipo publicado  y adaptado para textos del español de Cuba, hasta donde los autores conocen.
Para ello, 1) se crean conjuntos de datos a partir de provenientes del idioma inglés,
2) se proponen y entrenan los modelos y 3) se anotan
automáticamente las unidades de discurso argumentativas (UDA). Los atributos
utilizados para la representaciones de los textos son aprendidos en el proceso de entrenamiento 
para ajustarse al criterio argumentativo de los datos.
De los conjuntos de datos disponibles, se realizó un análisis de las ventajas y 
deficiencias de cada uno para la anotación de las ``Cartas a la Dirección'' del periódico cubano \textit{Granma}. 
Este análisis fue hecho por los autores y en un subconjunto de 30 de las Cartas, dada la no existencia de un conjunto anotado
de estas.
Los resultados obtenidos en la extracción de UDAs alcanzaron valores de
F1 = 0,82 comparados con 0,85 del estado del arte.
En las demás tareas, los resultados no son directamente comparables con los del estado del arte, 
debido a las diferentes aproximaciones tomadas en las investigaciones para
la extracción de argumentos.
Los mejores valores F1 obtenidos fueron 0,56 en la clasificación de UDAs, 0,74 en la predicción
de enlaces y 0,39 en la clasificación de enlaces.
}


\seplnkey{Argument extraction, natural language processing, deep learning.} % TODO Seguir en esto

\seplnabstract{
Argument Extraction is traditionally performed by manual annotation by linguistic experts, which takes lots of time. 
This paper proposes deep learning algorithms to perform the Argument Extraction in 
Cuban press texts, constituting the first of its kind published and adapted for Cuban Spanish texts, as far as the authors 
knowledge. To this end, 1) datasets are created by annotation projection from other ones in English language, 2) models are proposed and trained, 
and 3) automatic annotation of Argumentative Discourse Units (ADUs) is performed. The features used for text representations
are learned in the training process to match the argumentative criteria of the data. From the available data sets, an analysis 
of the advantages and deficiencies of each one was made for the annotation of the ``Letters to the Editor'' of the Cuban newspaper
\textit{Granma}. This analysis was done by the authors and on a subset of 30 of the Letters given the non-existence of an annotated set of 
it. The results obtained in the extraction of ADUs reached values of F1 = 0.82 compared to 0.85 of the state of the art. In 
the other tasks, the results are not directly comparable with those of the state of the art, due to the different approaches 
taken by the researchers when performing the arguments extraction. The best F1 values obtained 
were 0.56 in ADU classification, 0.74 in link prediction and 0.39 in link classification.
}

\firstpageno{1}


\begin{document}

% la siguiente instrucción sólo se debe usar si el abstract sobrescribe el texto
% la longitud variará según se necesite

\setlength\titlebox{25cm} % se aumenta el tamaño del espacio reservado para datos de título


\label{firstpage} \maketitle

%\begin{abstract}
%Resumen del artículo con una sangría a izquierda y derecha de 0.32
%cm, justificado por ambos lados, con tamaño de fuente 11.
%
%\end{abstract}

\section{Introducción}

% Contexto histórico-social donde se desarrolla
% Cuales son las condiciones historicas que hicieron necesarias la creacion de la tesis, o que dieron origen a la problematica de esta

La argumentación es una actividad verbal, social y racional destinada a convencer 
a un crítico razonable de la aceptabilidad de un punto de vista mediante la presentación 
de proposiciones que justifican o refutan la proposición expresada 
en el punto de vista \cite{van2004systematic}. 
% Esta definición concentra en ella 
% partes esenciales de lo que es la argumentación, dicha actividad se encuentra presente
% en varias facetas de la cotidianedad humana, como en la escritura o lectura de documentos y
% en las interacciones sociales de las personas. En resumen, la argumentación está presente 
% cada vez que se plantea un argumento y se trata de que este triunfe en un debate donde 
% se exponen elementos que lo apoyen.



% En la actualidad es necesario tener acceso a la información
% de forma rápida y simple. Esto no siempre es posible dado la gran cantidad de información existente y
% que es generada en cada momento. En caso de tener una vía de acceder a esta, se podrían realizar acciones
% con mayor rapidez y calidad. Con la argumentación, se podría hacer explícitas las razones de las personas 
% al afirmar algo sobre un tema teniendo así su punto de vista individual, y con suficientes personas, colectivo.

% Antecedentes del problema, justificación y motivación. 
% Antecedentes: 
%   Tareas similares que se quedan cortas: Opinion Mining, Citation Mining, Controversy Detection
%   Cómo se ha estudiado primero a mano. Trabajo dificil.
% Justificacion:
%   Limitaciones del trabajo manual
%   Se quiere hacer el trabajo automatico.
%   El proyecto esta integrado en un proyecto nacional  reconocido CORESPUC

Varias tareas en el Procesamiento de Lenguaje Natural (PLN) se han desarrollado alrededor
de diferentes problemas relacionados con 
la argumentación. Entre estas se encuentran: el minado de opiniones, sentimientos y 
emociones expresadas en un texto 
\cite{liu2010sentiment}, la detección de controversias, y la zonificación
argumentativa. 
% Estas tareas muestran cuáles opiniones, puntos de conflictos y roles 
% de argumentos 
% presenta el texto, pero lo realizan de manera separada y no muestran el porqué de estas. 

Es necesario realizar un 
análisis de los argumentos dados, para transformar el texto no estructurado a datos argumentativos 
que permitan el entendimiento de los puntos de vista y de cómo se ``apoyan'' o ``atacan'' entre sí. Este análisis
es posible realizarlo manualmente o utilizando programas
especializados para la anotación, aunque la práctica ha demostrado que este proceso requiere 
de una gran cantidad de tiempo y de personal calificado \cite{eger2018cross}. 
% Con la inmensa cantidad de datos 
% que se genera a diario este análisis es impracticable de realizar de forma manual, por esto se 
% estudian y crean métodos para automatizar esta tarea.

% Breve presentación de la problemática. 
%   Por todo lo anterior nace la EA, rama de PLN ..., definir tareas de la EA, tocar los enfoques realizados
% (No es el estado del arte aunque se puede hablar un poco de él) Elementos involucrados en el punto de vista cientifico, lleva corpus.

La Extracción de Argumentos (EA) es la rama del PLN encargada
del estudio de métodos para la extracción automática de las estructuras argumentativas de 
los textos y su posterior procesamiento \cite{lawrence2020argument}. Esta tarea se divide en 
cuatro subtareas fundamentales: i) la extracción y ii) clasificación de las componentes 
argumentativas del texto, y iii) la extracción y 
iv) clasificación de las relaciones entre estas. 

Esta es un área de investigación muy activa donde estas tareas han sido abordadas de diferentes maneras:
desde modelos secuenciales \cite{palau2009argumentation,goudas2015argument} hasta 
\textit{end-to-end} \cite{eger2017neural}, desde el uso de clasificadores clásicos 
como \textit{Naive Bayes} o máquinas de soporte vectorial (SVM, en inglés) \cite{niculae2017argument}, \cite{stab2017parsing} hasta el uso de 
aprendizaje profundo \cite{galassi2021deep}, \cite{mayer2020transformer}.

La EA se caracteriza por la poca disponibilidad de datos anotados y 
por la heterogeneidad de las 
anotaciones. Además, la gran mayoría de los estudios realizados en el campo se encuentran en 
idiomas como el inglés, alemán o chino \cite{eger2018cross}. 
En español, se reportan pocas investigaciones del análisis de los argumentos \cite{esteve2020mineria} y, en 
Cuba, no se encontró ninguna referencia, según la búsqueda de literatura científica
realizada por los autores.

% Actualidad, novedad e importancia teórica y práctica. 
%   En español no tiene mucho estudio. Citar casos del español, para Cuba ninguno
%   Creación de un corpus anotado el cual se podrá mejorar con el tiempo

% Diseño teórico.
%    Problema: 
%    Objeto de Investigación: Procesamiento de Lenguaje Natural
%    Campo de acción: Linguistica computacional
%    Hipótesis o preguntas científicas
%    Objetivos generales y específicos
%       General: Diseño e implementación de un algoritmo para el estudio de la argumentación en el periódico digital \textit{Granma}
%       Especifico Construcción del corpus de los periódicos: Crawler, Anotación (scpaCy).
%       Especifico Implementacion de la interfaz gráfica para consultar los resultados.

El objetivo, de esta investigación es proponer un algoritmo basado en aprendizaje profundo 
para la extracción y análisis de estructuras argumentativas en textos 
de la prensa cubana (en particular, la sección ``Cartas a la Dirección'' del períodico \textit{Granma}), 
constituyendo el primero de su tipo publicado y adaptado para
textos del español de Cuba, hasta donde los autores conocen. 
Para lograr dicho objetivo, en primer lugar, es necesario obtener mediante \textit{crawling} los textos a analizar del sitio 
web del periódico \textit{Granma}. Luego, se proponen algoritmos de aprendizaje automático capaces de realizar las tareas 
de EA sobre estos textos, que requiren conjuntos 
de datos anotados en español sobre los cuales se puedan entrenar.

Para la extracción
de argumentos se presentan dos modelos, el primero se encarga de la segmentación y clasificación
de las componentes argumentativas mediante la clasificación de los \textit{tokens} en etiquetas BIOES, que % TODO citar las etiquetas BIOES
delimitan y clasifican las unidades de discurso argumentativas (UDA). En el segundo, se analizan 
las posibles relaciones entre UDAs de manera independiente para saber si están relacionadas o no y saber
el tipo de relación existente. Los modelos utilizan 
redes neuronales convolucionales (CNN, en inglés), \textit{Long Short Term Memory} (LSTM, en inglés) \cite{hochreiter1997long} y \textit{Conditional Random Field} (CRF, en inglés) \cite{lafferty2001conditional}
como elementos principales en sus arquitecturas, además se emplean vectores GloVe \cite{pennington2014glove} para la representación
de las palabras. 
% Los algoritmos propuestos se aplican a textos del periódico \textit{Granma}, 
% en específico, se enfoca en su sección de ``Cartas a la Dirección''.

% Este es un modelo secuencia a secuencia en el cual las palabras 
% son vectorizadas por sus características morfológicas mediante el uso de redes neuronales convolucionales
% (CNN) y \textit{Long Short Term Memory} (LSTM), por su información
% semántica mediante \textit{embeddings} \textit{Global Vectors} (GloVe) y por su información 
% estructural mediante su parte de la oración, estas 
% secuencias son procesadas por una red LSTM bidireccional y sus atributos son usados por una capa 
% de \textit{Conditional Random Field} (CRF)
% para su clasificación final en etiquetas BIOES, con información adicional para la clasificación de las 
% unidades de discurso argumentativas (UDA). El segundo modelo está encargado de la extracción y clasificación 
% de las relaciones entre las UDAs. En él se utilizan las representaciones GloVe de las palabras en las secuencias 
% y su distancia argumentativa para la clasificación de una tupla en la que su primer elemento 
% constituye el texto candidato de donde parte la relación o fuente y el segundo, el texto candidato a recibir la 
% relación u objetivo, en el tipo de relación existente entre estos elementos. La entrada es procesada mediante 
% una LSTM bidireccional y módulos de atención cruzada entre los elementos de la fuente y los elementos del objetivo.
% Para la visualización se crea un ambiente de desarrollo con la herramienta Brat\footnote{\url{https://brat.nlplab.org/}},
% la cual permite realizar las tareas requeridas a los datos anotados por los modelos.

% En resumen, se presenta un estudio de la argumentación en español al realizar la extracción de 
% argumentos en prensa, tributando además conjuntos de datos anotados en español que puede servir
% para un estudio más profundo sobre los esquemas argumentativos presentes en estos textos.

% Estructura del trabajo % TODO para el final

El artículo se divide en varias secciones. Primero, se presentan las definiciones 
relativas a la argumentación y la EA. Luego, se presenta 
un estado del arte de la EA con una discusión de las
ventajas y desventajas de cada enfoque y se introduce la proyección de corpus. Más adelante, 
se presentan los modelos propuestos para resolver el problema en 
cuestión. A continuación se muestran los resultados del entrenamiento de los modelos y en 
la anotación de los textos de ``Cartas a la Dirección''. Finalmente, se exponen las conclusiones y 
recomendaciones de la investigación.

% ARGUMENTACION

% \section{Argumentación}

% Para el estudio de la argumentación han surgido algunos enfoques que componen un marco teórico 
% en donde se sustentan las investigaciones. Las ideas de \cite{perelman1969rhetoric} están
% enfocadas en un análisis de la retórica en donde se estipula que la teoría de la argumentación
% responde a provocar o aumentar la adhesión de las personas a las tesis presentadas, por medio de 
% técnicas discursivas. En \cite{toulmin_2003} se considera como argumento todo aquello que ofrece, 
% o todo lo que es utilizado, para justificar o refutar una proposición. En este último, se toma 
% una perspectiva más racional y deductiva de la argumentación, dando como resultado lo que se 
% conoce como el Método de Toulmin.

% La argumentación es un tema tratado desde la antigüedad, Aristóteles lo defendía como la 
% habilidad de, dada una pregunta, considerar los elementos útiles para persuadir a alguien, algo
% similar a la retórica. De una perspectiva más contemporánea surgen las ideas de 
% \cite{perelman1969rhetoric}
% enfocadas en un análisis de la retórica en donde se estipula que la teoría de la argumentación
% responde a provocar o aumentar la adhesión de las personas a las tesis presentadas, por medio de 
% técnicas discursivas. En 
% \cite{toulmin_2003}
% se considera como argumento todo aquello que ofrece, 
% o todo lo que es utilizado, para justificar o refutar una proposición. En este último, se toma 
% una perspectiva más racional y deductiva de la argumentación, dando como resultado lo que se 
% conoce como el Método de Toulmin. 

% \subsection{Método de Toulmin}

% Este método divide los argumentos en seis partes: afirmación 
% (\textit{claim}), fundamento (\textit{grounds}), justificación (\textit{warrant}), calificador 
% (\textit{qualifier}), refutación (\textit{rebuttal}) y respaldo (\textit{backing}).
% Mediante las afirmaciones se conoce el argumento principal que el autor quiere probar a la audiencia,
% estas son respaldadas con fundamentos, siendo estos las evidencias y hechos en que se apoya el autor.
% Las justificaciones pueden estar explícitas o implícitas y son suposiciones que vinculan los
% fundamentos con las afirmaciones, estas a su vez pueden ser respaldadas por conocimiento.
% El esquema introduce la posibilidad de otra situación válida a la establecida en las afirmaciones
% mediante la refutación. Los calificadores son usados para dar más información de la calidad o seguridad
% de las afirmaciones dadas. 
% Un ejemplo\footnote{Extraído de
% 	\cite{toulminArgument}.
% } de este esquema es:

% \begin{adjustwidth}{25pt}{25pt}
% 	[\textit{Se escucharon ladridos y aullidos en la distancia}]$_{\mathrm{fundamento}}$, 
% 	[\textit{probablemente}]$_{\mathrm{calificador}}$
% 	[\textit{haya perros en las cercanías}]$_{\mathrm{\text{afirmación}}}$.
% \end{adjustwidth}

% En este ejemplo, además de las partes explícitas, se encuentran partes implícitas como la justificación 
% (\textit{los perros son animales que ladran y aúllan}), el respaldo (\textit{se sabe que existen perros en la zona}) y 
% la refutación (\textit{puede ser que hayan lobos o coyotes cerca}).

% Este método crea una definición compacta que ayuda a los investigadores a enfocar su búsqueda 
% en las diferentes categorías definidas. Además, engloba de manera comprensible un tema tan complejo 
% como la argumentación al tomar en cuenta gran parte de los elementos presentes en el razonamiento
% realizado para llegar a conclusiones, incorporando incluso elementos probabilísticos en el proceso. 

% \subsection{Rasgos lingüísticos}

% Los rasgos lingüísticos son aquellas características que se encuentran presentes en los textos 
% que hacen que estos se clasifiquen argumentativos \cite{venegas2005hacia}. Con 
% la identificación de estos se hace la tarea de extracción más sencilla y con un marco teórico 
% que respalde las decisiones tomadas. Ejemplos de rasgos presentes en textos argumentativos:

% \begin{enumerate}
% 	\item Marcas de orden que introducen párrafos: \textit{primero}, \textit{segundo}, \textit{por un lado},
% 	      \textit{por otra parte}, \textit{finalmente}.
% 	\item Comillas y citas: citar palabras que refuercen la intervención recurriendo a autoridades
% 	      o personajes.
% 	\item Nexos que expresan causa o consecuencias: \textit{ya que}, \textit{porque}, \textit{pues},
% 	      \textit{con motivo de}, \textit{gracias a}, \textit{considerando que}, \textit{por lo tanto}, \textit{de manera que}.
% \end{enumerate}

% Estos rasgos además de dar indicación de la existencia de argumentos dan pie para conocer las relaciones
% entre estos y los tipos de argumentos. Por ejemplo, \textit{por lo tanto}, implica que lo que viene 
% a continuación es una conclusión apoyada en lo dicho anteriormente en el texto. Algo parecido
% sucede con \textit{ya que}, en este caso implica que lo siguiente es un argumento que se encuentra 
% relacionado con lo mencionado antes.

% En
% \cite{venegas2005hacia}
% se determinan 16 categorías y 51 rasgos lingüísticos, dando una idea 
% de la gran variedad de marcadores presentes en la argumentación.

\section{Extracción de Argumentos} %% RESUMED

La EA consiste en la identificación y extracción 
automática de las estructuras de inferencia y 
razonamiento expresadas como argumentos presentes en el lenguaje natural \cite{lawrence2020argument}.
La EA permite dar respuesta a este problema presentando
los argumentos y cómo sus relaciones justifican las posiciones del hablante. Dicho problema está constituido por diferentes 
estructuras y se compone de distintas tareas necesarias para su solución.

Existen diferentes estudios que conforman una metodología de análisis para
identificar los argumentos. El modelo de Toulmin \cite{toulmin_2003} introduce categorías 
con distintas funciones dentro de la argumentación. En 
el idioma español existen rasgos lingüísticos que, además de dar indicación de la existencia de argumentos, 
dan pie para conocer las relaciones entre estos y los tipos de argumentos. \namecite{venegas2005hacia}
determina 16 categorías y 51 rasgos lingüísticos, dando una idea de la gran variedad de marcadores 
presentes en la argumentación.

\subsection{Estructuras Argumentativas}

Las estructuras argumentativas son las partes de la argumentación de los textos y sus relaciones.
Estas se componen de dos elementos principales: las Unidades de Discurso Argumentativas (UDAs) y los enlaces
o relaciones existentes entre estas. Las UDAs corresponden a la unidad mínima de argumentación, definida 
como un segmento de texto que juega un solo rol para el argumento analizado, y es 
delimitado por segmentos vecinos que tienen roles diferentes o ningún rol \cite{stede2018argumentation}.

Las UDAs se relacionan entre sí conformando el proceso de inferencia y razonamiento del argumento.
Tanto los enlaces como las UDAs son clasificados en dependencia de su rol en la argumentación. Estas clasificaciones 
parten de los conceptos de afirmación, declaración controversial y parte central del argumento, y premisa, % TODO Poner referencias a los conceptos, o eliminarlos
razones que la justifican o refutan, y en las relaciones de ataque y apoyo. 

\subsection{Tareas de extracción de argumentos}

Dada la definición de estructuras argumentativas y que el objetivo de la EA es extraerlas,
se conciben las siguientes tareas principales:

\begin{enumerate}
	\item Extracción de UDAs: separar los segmentos de texto que formarán parte de la UDA.
	\item Clasificación de UDAs: asignar una categoría argumentativa a la UDA segmentada.
	\item Extracción de relaciones entre las UDAs: determinar si están relacionadas las UDAs o no.
	\item Clasificación de relaciones entre las UDAs: asignar una categoría a la relación extraída.
\end{enumerate}

% A continuación se presenta un ejemplo en donde se encuentran realizadas dichas tareas, clasificando
% las UDAs en afirmación y premisa y la relación en apoyo:

% \begin{adjustwidth}{25pt}{25pt}
% 	En primer lugar, [\textit{el correo electrónico puede contar como uno de los resultados
% 	más beneficiosos de la tecnología moderna}]$_{\mathrm{\text{Afirmación}}}$. [\textit{Años atrás, las personas pagaban gran cantidad de dinero para
% 	enviar sus cartas y sus pagos estaban sujetos al peso de sus cartas o paquetes y muchos accidentes podrían 
% 	causar problemas que causarían que el correo no fuera enviado}]$_{\mathrm{Premisa, -1, apoyo}}$.
% \end{adjustwidth}

% El -1 representa la distancia argumentativa, que es la cantidad de UDAs del texto que separan la 
% UDA fuente del objetivo \cite{galassi2021deep}, en caso de ser negativa (positiva) el objetivo se encuentra 
% antes (después) que la fuente.

% Puede observarse que las estructuras argumentativas de un texto constituyen un grafo dirigido 
% en donde sus nodos representan las UDAs y están etiquetados con su tipología, y sus aristas representan las 
% relaciones entre las UDAs. Dichas aristas se anotan con el tipo de relación existente entre ambas 
% (Figura \ref{fig:arg_struct}).

% \begin{figure}[h]
% 	\centering
% 	\includesvg[width=7cm]{Graphics/Estructuras_argumentativas.svg}
% 	\caption{Estructuras Argumentativas.}
% 	\label{fig:arg_struct}
% \end{figure}

% MARCO TEORICO

% \subsection{Representación de datos} 

% La representación de los datos constituye una parte importante al modelar un problema. Esta 
% es la encargada de presentar datos abstractos, como imágenes, párrafos o sonidos, en formas tratables
% por los algoritmos. Generalmente, se buscan configuraciones que recojan la mayor cantidad de información 
% de la entrada relevante al problema.

% En el PLN los datos suele estar representados con distintos niveles de granularidad.
% De menor granularidad a mayor se pueden ir mencionando los documentos, párrafos, oraciones, palabras y
% caracteres. Estos elementos es posible representarlos mediante vectores que codifiquen propiedades
% objetivas del problema a tratar como características morfológicas o semánticas de estos. Por ejemplo, 
% los textos tienen una popular manera de representarse mediante vectores de TF-IDF \cite{manning2008introduction},
% una desventaja de esta representación es que no toma en cuenta el orden de las palabras, por lo que 
% la representación de \textit{no me gusta,} y \textit{no, me gusta} serían iguales aunque semánticamente 
% sean opuestas. Para agregarle la información de orden a la representación se introducen los llamados 
% $n-$gramas, los cuales toman en cuenta una ventana de tamaño $n$ para conformar conjuntamente una representación.
% Este enfoque conlleva a la limitante de que solo un contexto finito está disponible para hacer las inferencias,
% para esto finalmente se crean representaciones individuales para cada palabra, las cuales codifican 
% información y la secuencia completa es introducida al modelo para realizar la inferencia.
% La manera más simple de representar una palabra es mediante la representación \textit{one-hot}, 
% en esta, a cada palabra se le asigna un índice y el vector resultante posee la dimensión del 
% vocabulario y es rellenado con ceros en todos sus elementos excepto en el índice de la palabra, donde se le asigna 1.
% Esta representación asume que las palabras son independientes entre sí y 
% computacionalmente ocupan un espacio considerable. Existen otras representaciones 
% que brindan información al algoritmo sobre la morfología y la semántica de la palabra que representa.

% Las características morfológicas son aquellas que describen cómo está formado el elemento a analizar.
% Estas pueden ser extraídas con relativa facilidad, entre tales características se encuentran: tamaño, 
% cantidad, posición de palabras o párrafos, presencia de sufijos, prefijos, acentos u otros marcadores
% en el texto. Las características semánticas presentan una mayor dificultad a la hora de ser extraídas.
% Para esto se utilizan diferentes modelos que codifican esta información en vectores continuos conocidos como 
% \textit{embeddings}, entre los modelos existentes se encuentran
% word2vec \cite{mikolov2013efficient}, 
% \textit{Global Vectors} (GloVe) \cite{pennington2014glove}, 
% \textit{Bidirectional Encoder Representations from Transformers} (BERT) \cite{devlin2018bert},
% entre otros.

% \subsection{Modelación de problemas}

% Los problemas en la vida real se presentan en un principio como una descripción a un nivel de abstracción 
% más alto que el requerido por los algoritmos existentes, se hablan de entidades abstractas como imágenes,
% sonidos, textos o usuarios, además de la información que se desea extraer o las operaciones que se
% desean aplicar sobre estas entidades. A lo largo del desarrollo del AA han aparecido diferentes tipos de problemas 
% que aparecen frecuentemente en la práctica y sus respectivas maneras de solucionarlos. Uno de estos tipos de problemas
% es el de secuencia a secuencia (\textit{seq2seq}), cuyo objetivo es la conversión de una secuencia en un dominio de entrada a otra 
% secuencia en un dominio de salida. Con este tipo de problemas se modelan tareas como traducción automática, en 
% donde el dominio de entrada es texto en un lenguaje de partida y el dominio de salida es texto en un lenguaje de llegada.
% Otro problema que se resuelve con \textit{seq2seq} es la segmentación de texto, cuya entrada es una lista de \textit{tokens}
% y la salida son etiquetas que indican cuándo empieza y termina un segmento de texto. Las etiquetas utilizadas para 
% la segmentación, generalmente, son:

% \begin{itemize}
% 	\item B (\textit{begin}): representa el inicio del segmento.
% 	\item I (\textit{inside}): representa la continuación del segmento previamente iniciado.
% 	\item O (\textit{outside}): representa la no pertenencia a un segmento.
% \end{itemize}

% Este esquema presenta una versión más elaborada en la que se agregan dos clases que representan el final 
% de un segmento E (\textit{end}) y un segmento de un solo elemento S (\textit{single}). La tarea anterior es 
% utilizada como base para otra un poco más compleja, en la que, además de segmentar el texto, se desea 
% clasificar sus segmentos. Para este problema se añaden meta etiquetas correspondientes a los tipos a identificar $C$
% obteniendo un conjunto final $R = \{ B, I, E, S \} \times C \cup \{ O \}$. En tareas como la extracción de entidades
% nombradas este método es empleado, donde el conjunto $C$ contiene las posibles categorías de entidades a identificar.

% \subsection{Arquitecturas}

% En aprendizaje profundo existen una gran cantidad de arquitecturas que se pueden utilizar para formar el modelo 
% final. Estas deben de ser seleccionadas en dependencia de los datos y el problema a tratar, ya que sus diseños 
% emulan diferentes operaciones sobre datos que pueden ser más beneficiosas en situaciones específicas.

% \subsubsection{Capas densas}

% El perceptrón consiste es una transformación lineal del vector de datos $\textbf{x}$ con un sesgo $b$ y 
% luego aplicar una transformación no lineal $g$, conocida como función de activación, 
% para la obtención del resultado final:

% \begin{equation}
% 	f(\textbf{x}) = g(\textbf{w}\textbf{x} + b).
% \end{equation}

% El perceptrón constituye la unidad básica de las capas densas, ya que estas consisten en la aplicación
% de este modelo varias veces sobre la misma entrada $\textbf{x}$ produciendo vectores de la dimensión $k$
% deseada como salida final. Los parámetros se codifican en la matriz $\textbf{W}$ y sus sesgo en el 
% vector $\textbf{b}$:

% \begin{equation}
% 	f(\textbf{x}) = g(\textbf{Wx} + \textbf{b}).
% \end{equation}

% Para las funciones de activación existen varias elecciones. Una de estas es la función sigmoidal. 
% Esta devuelve un valor entre 0 y 1, es usada en tareas de regresión logística. 
% Se puede interpretar como el nivel de activación de la neurona:

% \begin{equation}
% 	sigm(x) = \frac{1}{1-e^{-x}}.
% \end{equation}

% \textit{Rectified Linear Unit} (ReLU) se define como la parte positiva del argumento. Una ventaja que trae esta 
% función de activación es su rápido cálculo de su derivada y que previene en parte de los problemas 
% de desaparición de gradiente de la sigmoidal:

% \begin{equation}
% 	relu(x) = \max(0, x).
% \end{equation}

% La función de activación \textit{softmax} es diferente a las anteriores en el sentido que necesita
% el vector salida de la capa anterior para ser computada. Esta función convierte las $q$ salidas
% en una distribución de probabilidad, algo necesario en tareas de clasificación:

% \begin{equation}
% 	softmax_k(\textbf{x}) = \frac{e^{x_k}}{\sum\limits_{i=1}^{q} e^{x_i}}.
% \end{equation}

% \subsubsection{Redes Neuronales Convolucionales}

% Las redes neuronales convolucionales (CNN, en inglés) 
% son un tipo de redes usadas
% principalmente para tratar datos donde su estructura espacial es relevante, por ejemplo,
% en datos bidimensionales como imágenes y en unidimensionales como sonido y texto.
% Estas redes aplican de una función de kernel sobre los datos, $f * g$ donde $f$ son los
% datos, $g$ es el kernel o filtro y $*$ es el operador de convolución \cite{d2l}. La función $g$ se puede 
% aprender en el proceso o también puede ser una función de agrupación predefinida. 
% Un ejemplo bidimensional de una función de kernel se muestra en la Figura \ref{fig:conv_kernel}.

% \begin{figure}[h]
% 	\centering
% 	\includegraphics[width=7cm,clip]{Graphics/kernel_convolution.png}
% 	\caption{Convolución con kernel (Tomado de \cite{d2l} pág. 241).}
% 	\label{fig:conv_kernel}
% \end{figure}

% En este se observa cómo una nueva representación es computada al operar el kernel por la matriz de datos. Este
% corrimiento se puede realizar de diferentes formas, por ejemplo, se puede mover de dos en dos en vez de uno en uno, este
% parámetro se le conoce como tamaño de paso (\textit{stride}). Es posible además preservar las dimensiones
% iniciales de los datos al aplicarle un aumento de los datos en los bordes de tal forma que el resultado sea de la misma
% dimensión, este aumento se realiza, generalmente, rellenando convenientemente los espacios con ceros, 
% a esto se le llama \textit{padding} (Figura \ref{fig:conv_kernel_padding}).

% \begin{figure}[h]
%     \centering
% 	\includegraphics[width=7cm,clip]{Graphics/kernel_convolution_padding.png}
% 	\caption{Convolución con kernel con \textit{padding} (Tomado de \cite{d2l} pág. 241).}
% 	\label{fig:conv_kernel_padding}
% \end{figure}

% Existen varias funciones de agrupación usadas. Entre estas se encuentran las de agrupación máxima y de 
% agrupación media. Como sus nombres indican, la de agrupación máxima devuelve el valor máximo de los encontrados
% en la ventana del kernel, la de media calcula el promedio de estos valores. Estas capas tienen la capacidad de obtener
% información resumida sobre los datos.

% \subsubsection{Redes Residuales}

% Al crear modelos de aprendizaje profundo se tienen un conjunto de parámetros $\theta$. Las posibles combinaciones 
% de estos forman un espacio de funciones $F$ al cual pertenecen todas las posibles instancias del modelo.
% Agregar nuevas capas aumenta la complejidad de este, pero no hay garantía de que el viejo espacio 
% de funciones $F$ sea subconjunto del nuevo espacio $F'$, lo que implica que el nuevo modelo no es necesariamente
% estrictamente superior al antiguo. Este problema es la razón para la aparición de las Redes Residuales. 
% Una red residual está formada por 
% uno o varios bloques residuales, en los que a la salida de cada bloque residual le es sumada la entrada de 
% este mediante una conexión residual.
% El objetivo de realizar tal operación es que es posible hacer la contribución del bloque 0 obteniendo así
% un modelo equivalente a uno sin el bloque, garantizando la condición de subconjunto $F \subset F'$, además,
% dicho bloque no pierde poder expresivo, dado que en caso de que su aporte al resultado final sea considerable, 
% se tendría que aprender solamente la función $f(x) - x$ donde $x$ es la entrada del bloque y $f$ es la función 
% aprendida por el bloque sin la conexión residual, para mitigar el efecto de la conexión residual como se muestra
% en la Figura \ref{fig:res_block}.

% \begin{figure}[h]
%     \centering
% 	\includegraphics[width=7cm,clip]{Graphics/resnet.png}
% 	\caption{Bloque residual (Tomado de \cite{d2l} pág. 289).}
% 	\label{fig:res_block}
% \end{figure}

% \subsubsection{Redes Neuronales Recurrentes}

% Las redes neuronales recurrentes (RNN, en inglés) son
% un tipo especial de arquitectura especializada en el trabajo con datos secuenciales. Este tipo de arquitectura
% presenta variables en las que se almacenan información pasada, que es usada para el computo de la salida. El 
% problema se puede modelar probabilísticamente mediante la estimación de $P(x_t | x_{t-1}, \dots, x_{1})$,
% donde existen dos variantes principales. En una variante se fija un tamaño de ventana $\alpha$ en el tiempo, 
% dando como resultado $P(x_t | x_{t-1}, \dots, x_{t-\alpha})$, a este tipo de modelos se les conoce como autorregresivos. 
% Otra estrategia consiste en guardar un contexto de observaciones pasadas $h_t$ y con este realizar la estimación 
% $P(x_t | h_t)$, el contexto se actualiza en cada paso mediante una función $h_t = g(h_{t-1}, x_{t-1})$, a estos 
% se les nombra modelos autorregresivos latentes, debido a la existencia de variables ocultas $h_t$. 

% En la práctica estos modelos presentan problemas de gradientes, ya que estas pueden volverse extremadamente grandes o 
% desaparecer.
% Para esto se han creado arquitecturas que disminuyen estos problemas. Una de estas arquitecturas es las de memorias
% de corto largo plazo (LSTM, en inglés) \cite{hochreiter1997long}.
% Este modelo guarda un contexto del procesamiento y está constituido por varias compuertas que regulan las 
% actualizaciones de los estados internos. LSTM (Figura \ref{fig:rnn_lstm}) posee dos variables de estado, la memoria 
% $C$ y el estado oculto $H$. Entre sus compuertas se encuentran la compuerta de olvido, esta regula cuánto de la 
% memoria permanece en el próximo paso, la compuerta de entrada ajusta la cantidad de información nueva que entrará, 
% la compuerta de salida maneja el cálculo del próximo estado oculto.

% \begin{figure}[h]
%     \centering
% 	\includegraphics[width=7cm,clip]{Graphics/rnn_lstm.png}
% 	\caption{LSTM (Tomado de \cite{d2l} pág. 357).}
% 	\label{fig:rnn_lstm}
% \end{figure}

% El método de aprendizaje de las RNN solamente observa los elementos anteriores de la secuencia, aunque existen
% tareas en las que, observando los elementos posteriores, se brinda más contexto e información a la tarea, sin que interfiera
% en el proceso de inferencia. El modelo bidireccional presenta una alternativa para tratar con este tipo de problemas, 
% este modelo consiste en, además de hacer el recorrido de inicio a final de la secuencia, realizar otro recorrido en orden 
% inverso (Figura \ref{fig:rnn_bidirectional}), estos recorridos van generando dos estados ocultos $\overrightarrow{H}_{i}$ y $\overleftarrow{H}_{i}$
% que luego son mezclados para obtener el contexto final $H_i$, los tipos de mezclas comunes son la concatenación de los 
% estados o la multiplicación elemento a elemento de estos.

% \begin{figure}[h]
%     \centering
% 	\includegraphics[width=7cm,clip]{Graphics/rnn_bidirectional.png}
% 	\caption{Red neuronal bidireccional (Tomado de \cite{d2l} pág. 367).}
% 	\label{fig:rnn_bidirectional}
% \end{figure}


% \subsubsection{Atención}

% % Definicion, qué hace, uso en secuencias
% La atención es una técnica en la cual se hace una selección ponderada de atributos en un contexto específico. 
% Este mecanismo presenta dos partes, una consulta $q$ y una colección de pares llave-valor, $(k_i, v_i)$. La 
% consulta representa el contexto en donde se quiere aplicar la atención y las llaves $k_i$ son elementos que 
% relacionan la consulta a los valores $v_i$. El proceso de calcular el resultado consiste en, primero, calcular 
% el vector compatibilidad $e$ entre las llaves y la consulta mediante la función $f$, este vector es luego 
% modificado por una función $g$ que distribuye los valores obteniendo el vector atención $a$. Finalmente 
% este vector es utilizado para calcular el resultado final al aplicarle la función $o = z(a, V)$:

% \begin{equation}
% 	e = f(q, K),
% \end{equation}
% \begin{equation}
% 	a = g(e),
% \end{equation}
% \begin{equation}
% 	o = z(a, V).
% \end{equation}

% En dependencia de cómo se seleccionen las funciones $f$, $g$ y $z$ se pueden obtener distintos tipos de atención.
% Una configuración simple consiste en definir $f$ como el producto punto de la consulta con la llave,
% $g$ como \textit{softmax} y $z$ la suma ponderada de $v_i$ con los valores de atención.

% \subsubsection{Campo Aleatorio Condicional}

% % Definicion de CRF, qué modela, Ventajas de CRF en secuencias, mirar relacion con Hidden Markov Models

% El campo aleatorio condicional (CRF, en inglés) es un 
% tipo de modelo gráfico probabilístico que trabaja eficientemente con secuencias,
% modelando conjuntamente la probabilidad de las etiquetas de sus elementos dadas sus observaciones \cite{lafferty2001conditional}.
% En trabajos de secuencias, la forma más simple que toma el grafo consiste en una cadena de las variables representando
% las etiquetas de las secuencias $Y$, conectadas de la forma $(Y_i, Y_{i+1})$ y las variables observadas $X$, conectadas
% a las variables $Y$ \cite{wallach2004conditional}.

% El objetivo de CRF es calcular la secuencia $Y^*$ tal que:

% \begin{equation}
% 	Y^* = \arg \max_Y P(Y | X).
% 	\label{eq:crf}
% \end{equation}

% En esta expresión se observa que devuelve la secuencia más probable, dadas las variables observadas o atributos $X$,
% por lo que esta capa es usada al final del proceso para problemas de clasificación de secuencias.

% \subsection{Evaluación del modelo y métricas}

% Los modelos de AA necesitan maneras de expresar qué tan buenos son 
% en las tareas encomendadas. Para esto se crean funciones que evalúan los resultados obtenidos
% por dichos modelos, estas funciones se les da el nombre de métricas. Existen diferentes tipos de
% métricas para tratar con diferentes tipos de problemas. En aprendizaje supervisado una métrica se
% define como una función $m_s(Y, \hat{Y})$, donde $Y$ son las predicciones verdaderas y $\hat{Y}$ son las predicciones
% hechas por el modelo. En algoritmos de aprendizaje no supervisado como K-Means y K-NN son usadas funciones $m_{ns}(\hat{Y})$
% donde $\hat{Y}$ son las predicciones finales. En comparación con su versión supervisada estas funciones no tiene acceso
% a las predicciones verdaderas del problema.

% \subsubsection{Clasificación}

% En problemas de clasificación (problemas en donde las etiquetas a predecir son discretas) 
% son empleadas medidas que toman en cuenta la naturaleza discreta de su conjunto imagen.
% Medidas como precisión, recobrado, \textit{accuracy} y F1 son utilizadas en la 
% evaluación de los resultados, mientras que como función de error se usa entropía cruzada 
% (\textit{cross entropy} en inglés) \cite{grandini2020metrics}.

% La matriz de confusión es una vía de representar los resultados de dos clasificadores. Esta matriz en $M_{ij}$
% indica la cantidad de elementos que clasificó como clase $i$ el primer clasificador y
% como clase $j$ el segundo clasificador. En su uso práctico,
% un clasificador son las etiquetas verdaderas mientras que el otro es el clasificador que se está evaluando. 
% En problemas de la clasificación binaria, donde se busca saber si existe pertenencia o no de un elemento a una clase,
% se pueden observar los siguientes casos:

% \begin{itemize}
% 	\item Verdaderos Positivos (VP): elementos clasificados correctamente que pertenecen a la clase.
% 	\item Verdaderos Negativos (VN): elementos clasificados correctamente que no pertenecen a la clase.
% 	\item Falsos Positivos (FP): elementos que no pertenecen a la clase clasificados incorrectamente en que pertenecen.
% 	\item Falsos Negativos (FN): elementos que pertenecen a la clase clasificados incorrectamente en que no pertenecen.
% \end{itemize}

% \begin{table}[h]
% 	\begin{center}
% 		\begin{tabular}{|l|c|c|} 
% 			\hline\rule{-2pt}{15pt}
% 			{\bf Clases}   & {\bf Positivo} & {\bf Negativo} \\ 
% 			\hline\rule{-4pt}{10pt}
% 			Positivo & VP       & FN       \\ 
% 			Negativo & FP       & VN       \\ 
% 			\hline
% 		\end{tabular}
% 	\end{center}
% 	\caption{\label{fig:confusion_matrix}Matriz de confusión binaria.}
% \end{table}

% La precisión es la medida que indica la probabilidad de que la clasificación de una clase sea correcta. Esto 
% se puede observar como la proporción de los elementos correctamente clasificados sobre el total de 
% elementos clasificados:

% \begin{equation}
% 	prec_i = \frac{VP}{VP + FP}.
% \end{equation}

% En problemas de clasificación múltiple surge la versión macro de esta medida calculada como la media de todas
% las precisiones de las clases existentes:

% \begin{equation}
% 	prec_{macro} = \sum^K_{i=1} \frac{prec_i}{K}.
% \end{equation}

% El recobrado es la medida que indica la probabilidad de que se clasifique correctamente un elemento de la clase
% del total existente. Esto se puede observar como la proporción de los elementos correctamente clasificados sobre el 
% total de elementos que pertenecen a la clase:

% \begin{equation}
% 	rec_i = \frac{VP}{VP + FN}.
% \end{equation}

% En problemas de clasificación múltiple surge la versión macro de esta medida calculada como la media de todos
% los recobrados de las clases existentes:

% \begin{equation}
% 	rec_{macro} = \sum^K_{i=1} \frac{rec_i}{K}.
% \end{equation}

% La medida F1 es la media armónica de la precisión y el recobrado. En esta la contribución de la precisión y el
% recobrado al resultado final es el mismo, aunque es posible buscar variaciones de acuerdo a al problema a tratar:

% \begin{equation}
% 	F1_i = 2 \frac{prec_i \cdot rec_i}{prec_i + rec_i}.
% \end{equation}

% En problemas de clasificación múltiple surge la versión macro de esta medida calculada la propia medida F1, pero
% utilizando la precisión y recobrado macro del problema:

% \begin{equation}
% 	F1_{macro} = 2 \frac{prec_{macro} \cdot rec_{macro}}{prec_{macro} + rec_{macro}}.
% \end{equation}

% La métrica $\alpha$\%F1 \cite{persing2016end} es una métrica basada en la idea de F1 orientada para el 
% trabajo con secuencias donde $\alpha$ denota el porcentaje de secuencia inferida que debe coincidir con 
% la secuencia anotada para ser considerado una coincidencia. Esta versión permite
% establecer el rango de flexibilidad si $\alpha=100$ (100\%F1), significa que deben coincidir completamente, 
% mientras si $\alpha = 50$ (50\%F1) significa que, si coinciden en una proporción mayor o igual a la mitad, 
% se considera como un verdadero positivo. La definición de los valores de verdaderos positivos, negativos 
% y falsos negativos es:

% \begin{equation}
% 	VP = |\{ j | \exists i | gl(j) = pl(i) \land i = j \}|,
% \end{equation}
% \begin{equation}
% 	FP = |\{ i | pl(i) \neq n \land \not\exists j | gl(j) = pl(i) \land i = j \}|,
% \end{equation}
% \begin{equation}
% 	FN = |\{ j | \not\exists i | gl(j) = pl(i) \land i = j \}|,
% \end{equation}

% donde $i$ y $j$ son las UDAs extraídas, $gl(j)$ es la etiqueta correcta para $j$, $pl(i)$ es 
% la etiqueta inferida para $i$, $n$ es la clase no argumentativa, $i = j$ significa que $i$ es 
% una coincidencia para $j$.

% Las métricas anteriores están acotadas por los valores 0 y 1, donde 1 representa la mejor evaluación y 0 la 
% peor.

% La entropía cruzada se encarga de evaluar qué tan diferentes son dos funciones de distribución $p$ y $q$, su 
% resultado es un número no negativo que, a medida que sean más pequeños los valores, indican mayor similitud. 
% En su versión discreta se formula:

% \begin{equation}
% 	H(p, q) = - \sum_{x \in D} p(x) \log q(x).
% \end{equation}

% \subsubsection{Cadenas}

% Para textos o cadenas existen diferentes métricas que constituyen formas de saber la similitud 
% entre dos elementos. Una de esas métricas es la similitud de Jaccard, esa se puede ver como 
% la proporción de elementos comunes que presentan dos conjuntos, los elementos sería palabras:

% \begin{equation}
% 	jac(X, Y) = \frac{|X \cap Y|}{|X \cup Y|}.
% \end{equation}
% Otra medida de similitud es la distancia de Levenshtein, la cual se define como la mínima cantidad 
% de cambios de eliminar, cambiar y agregar que se tienen que hacer a dos secuencias para que sean 
% iguales. Esta medida se puede usar tanto en palabras, en donde se mediría la cantidad de cambios 
% a los caracteres, como en listas de palabras, donde se mediría la cantidad de palabras que 
% se tienen que cambiar. 

% \subsubsection{Curvas de aprendizaje}

% Es necesario además de evaluar el resultado final del modelo, evaluar el proceso de entrenamiento. En esta etapa 
% se pueden diagnosticar varias deficiencias en este proceso. Para un correcto entrenamiento se divide el conjunto de 
% datos en tres partes:

% \begin{itemize}
% 	\item \textbf{entrenamiento}: utilizada para el entrenamiento del modelo.
% 	\item \textbf{validación}: utilizada para evaluar el desempeño del modelo durante el entrenamiento.
% 	\item \textbf{prueba}: utilizada para evaluar el resultado final.
% \end{itemize}

% Las curvas de aprendizaje constituyen la principal herramienta para evaluar el proceso de aprendizaje.
% Estas están formadas por las mediciones de métricas a lo largo del entrenamiento calculadas a partir de 
% los conjuntos de validación y entrenamiento. En estas, el eje horizontal representa el número de época del entrenamiento,
% iteración sobre el conjunto de entrenamiento, y el eje vertical representa el valor de la métrica a analizar. 
% La línea correspondiente al conjunto de entrenamiento cuantifica 
% el aprendizaje del modelo o también el error de entrenamiento, y la correspondiente a la de validación cuantifica 
% la generalización o el error de generalización. Existen tres comportamientos esenciales a analizar:

% \begin{itemize}
% 	\item Bajo ajuste (\textit{underfitting}).
% 	\item Sobreajuste (\textit{overfitting}).
% 	\item Buen ajuste.
% \end{itemize}

% El bajo ajuste ocurre cuando el modelo no es capaz de aprender del conjunto de datos o cuando este aún puede aprender 
% más. Las curvas de aprendizaje en estos casos se caracterizan por ser una línea plana o valores ruidosos con alta pérdida
% (Figura \ref{fig:underfit}).

% \begin{figure}[h]
% 	\centering
% 	\includegraphics[width=7cm,clip]{Graphics/underfit_missing_training.png}
% 	\includegraphics[width=7cm,clip]{Graphics/underfit_not_learning.png}
% 	\caption{Curvas de entrenamiento con bajo ajuste por falta de entrenamiento (arriba)
% 		y por modelo que no aprende de los datos (abajo) (Tomado de \cite{brownlee2018better} pág. XXVII).}
% 	\label{fig:underfit}
% \end{figure}

% Entre las formas más sencillas de combatir el bajo ajuste de los modelos consiste en complejizarlo, al añadir
% capas o aumentar las dimensiones de este aumenta su expresividad y, por lo tanto, su ajuste. Si este método 
% no funciona es posible considerar un cambio de arquitectura hacia una que pueda extraer más información de la 
% estructura de los datos. 

% El sobreajuste es el fenómeno en el que el modelo aprende los datos de entrenamiento extremadamente bien, incluso
% el ruido en estos, esto trae consigo que falla en generalizar el problema para nuevas entradas. Las curvas 
% características de este fenómeno presentan una divergencia en los errores de entrenamiento y validación a medida
% que se entrena el modelo, mientras que la de entrenamiento mejora la de validación tiende a empeorar (Figura \ref{fig:overfit}). 

% \begin{figure}[h]
% 	\centering
% 	\includegraphics[width=7cm,clip]{Graphics/overfit_raising_val_error.png}
% 	\caption{Curvas de entrenamiento con sobreajuste (Tomado de \cite{brownlee2018better} pág. XXIX).}
% 	\label{fig:overfit}
% \end{figure}

% Existen varios métodos para combatir el sobreajuste, uno sencillo es simplificar el modelo quitándole capas 
% o disminuyendo sus dimensiones. Además de esto, existen regularizaciones que se pueden aplicar para evitar que 
% las capas dependan exclusivamente de pocos atributos, entre esta familia los más usados son la regularización
% L1 y L2 las cuales se definen como la suma del valor absoluto de los atributos y la suma del cuadrado de sus 
% atributos respectivamente. Otra medida para prevenir el sobreajuste es el agrego de capas de abandono 
% (\textit{dropout}). Estas capas desactivan neuronas de la arquitectura, obligando a 
% estas a ser robustas y depender del comportamiento de la población, en lugar de la actividad de otras unidades 
% específicas \cite{baldi2013dropout}. La terminación temprana (\textit{early stopping}) del entrenamiento
% se utiliza para parar este en el momento en que el error de generalización comienza a subir, impidiendo así que 
% se sobreentrene el modelo.

% Finalmente, un buen ajuste es el resultado que se alcanza cuando tanto la curva de validación como de entrenamiento
% presentan valores pequeños y similares, consecuentes con una correcto aprendizaje y generalización (Figura \ref{fig:good_fit}).

% \begin{figure}[h]
% 	\centering
% 	\includegraphics[width=7cm,clip]{Graphics/good_fit.png}
% 	\caption{Curvas de entrenamiento con buen ajuste (Tomado de \cite{brownlee2018better} pág. XXX).}
% 	\label{fig:good_fit}
% \end{figure}

% Otro problema observable a partir del análisis de las curvas de aprendizaje constituye la detección de conjuntos
% de datos no representativos. Un conjunto de datos no representativo es uno que puede no 
% capturar las características estadísticas relativas a otro conjunto de datos extraído del mismo dominio.
% Esto puede pasar que los conjuntos de entrenamiento o de validación. En caso del conjunto de entrenamiento
% se puede identificar si la pérdida en el conjunto de entrenamiento conlleva a una ganancia en el conjunto de 
% validación y viceversa quedando al final con una separación entre ambos valores. En el caso del conjunto de 
% validación se presenta como una curva ruidosa, también se puede dar el caso de que el conjunto  de validación
% sea más fácil de predecir que el de entrenamiento, en este caso se observa como la curva de validación permanece
% siempre por debajo de la de entrenamiento (Figura \ref{fig:unrepresentative_data}).

% \begin{figure}[h]
% 	\centering
% 	\includegraphics[width=7cm,clip]{Graphics/unrepresentative_dev_set.png}
% 	\includegraphics[width=7cm,clip]{Graphics/unrepresentative_train_set.png}
% 	\caption{Curvas de entrenamiento con datos poco representativos en el conjunto de validación (arriba)
% 		y en el conjunto de entrenamiento (abajo) (Tomado de \cite{brownlee2018better} pág. XXXII).}
% 	\label{fig:unrepresentative_data}
% \end{figure}

% Para combatir estos problemas se puede aumentar la cantidad de elementos en los conjuntos de entrenamiento o 
% validación en dependencia de donde ocurra.

% \subsection{Aumento de datos}

% El aumento de datos consiste en acciones para aumentar la diversidad de un conjunto de datos sin recolectar
% nuevos datos explícitamente \cite{feng2021data}. En datos continuos, como imágenes o valores numéricos el 
% aumento de datos puede ser realizado al añadirle perturbaciones a entradas existentes, en caso de las imágenes 
% técnicas como el volteado (\textit{flipping}) o recortado (\textit{cropping}) son usadas. Los textos son un tipo 
% de datos discreto y, por lo tanto, las técnicas anteriores no pueden ser aplicadas directamente. Para el PLN
% se han estudiado diversas técnicas de aumento de datos, una de estas consiste en el cambio del árbol de 
% dependencia de la oración mediante operaciones de intercambio y borrado de nodos \cite{csahin2019data}, también se han utilizado 
% el intercambio de palabras por sinónimos \cite{dai2020analysis} y la traducción de textos hacia un lenguaje y luego 
% de vuelta al lenguaje origen (\textit{backtranslation}) \cite{sennrich2015improving}. 

% \subsection{Aprendizaje Conjunto}

% El aprendizaje conjunto (\textit{ensemble learning}) son técnicas encaminadas al aprovechamiento
% de soluciones encontradas por diferentes modelos, combinándolas y mejorándolas para encontrar una mejor solución 
% al problema. Estos métodos son efectivos en la reducción de la varianza y el sesgo de los modelos, obteniendo así
% mejores resultados \cite{dietterich2002ensemble}. Una forma de este tipo de aprendizaje en problemas de 
% clasificación constituye el voto conjunto, en donde los diferentes clasificadores votan sobre la clase a la que 
% pertenece el elemento y, al final, se asigna la etiqueta que más votos obtuvo.

% \subsection{Métodos de optimización}

% El objetivo del AA es encontrar los extremos de una función de costo, este proceso es una tarea 
% desafiante ya que la gran mayoría de estas funciones no son convexas y, por lo tanto, no existe un algoritmo
% que asegure la convergencia hacia un extremo global. Para resolver este problema existen múltiples heurísticas,
% la más usada es el descenso por gradiente. La idea básica consiste 
% en el cálculo del vector gradiente de la función de error $f$ con respecto a los parámetros del modelo $x$ y, una vez se 
% tiene dicho vector, se evalúa en la asignación actual de los parámetros $x_i$ y se realiza un corrimiento de este punto 
% en contra del gradiente para disminuir el error (Eq. \ref{eq:gradien_descent}).

% \begin{equation}
% 	x_{i+1} = x_i - \alpha \nabla f(x_i)\label{eq:gradien_descent}
% \end{equation}

% En la ecuación \ref{eq:gradien_descent} anterior, $\alpha$ es la tasa de aprendizaje (\textit{learning rate}),
% que cuantifica cuánto se toma del vector de gradiente para actualizar los parámetros, esto 
% se puede ver como el aprendizaje del modelo.

% Variantes eficientes de este algoritmo para el entrenamiento de modelos de AA han sido 
% creadas, las variaciones se encuentran principalmente en la selección de $\alpha$ en cada paso y la 
% selección de los conjuntos de datos con que se estimará el gradiente. Entre las técnicas utilizadas se 
% encuentran Descenso por Gradiente Estocástico, variaciones de tasa de aprendizaje dinámica con 
% sus diferentes variantes (exponencial, polinómica), RMSProp \cite{tieleman2012rmsp}
% y Adam \cite{kingma2014adam}.

% INVESTIGACIONES PREVIAS

\subsection{Variantes para la Extracción de Argumentos}

Varias investigaciones han dado respuesta a los problemas asociados a EA, mostrando
una variedad en enfoques y métodos.\\

En \cite{palau2009argumentation} se analizan las UDAs a nivel de oraciones.
Este propone \textit{Naive Bayes} (NB) y máquinas de soporte vectorial (SVM, en inglés) para la clasificación
de oraciones de oraciones en argumentativas o no. Las oraciones son representadas
on un vector conformado de atributos a partir de conocimiento experto de la argumentación. En
la predicción de relaciones utilizan una gramática libre de contexto.

% \begin{itemize}
% 	\item Se analizan las UDAs a nivel de oraciones.
% 	\item Propone \textit{Naive Bayes} (NB) y \textit{Support Vector Machine} (SVM) para la clasificación
% 	de oraciones de oraciones en argumentativas o no.
% 	\item Las oraciones se representan con un vector conformado de atributos a partir de conocimiento experto
% 	de la argumentación.
% 	\item Para la predicción de relaciones utilizan una gramática libre de contexto. 
% \end{itemize}

% En \cite{palau2009argumentation} se propone
% el uso de modelos como \textit{Naive Bayes} (NB) y \textit{Support Vector Machine} (SVM)
% para la clasificación de 
% oraciones en argumentativas o no y en su rol argumentativo en caso de que sea argumentativa. En este
% se asume que las componentes argumentativas son oraciones completas. Para la predicción de relaciones
% se usa un enfoque basado en reglas con la creación de una Gramática Libre de Contexto. Las representaciones
% de las oraciones consisten en atributos creados a mano, dado el conocimiento experto sobre la argumentación
% en el tema tratado, elementos como adverbios, verbos, signos de puntuación, palabras clave, estadísticas del texto
% (tamaño de oración, distancia media de palabras) son usados para la extracción y clasificación de las UDAs, además,
% se usan también como base en la creación de las reglas de la gramática para la extracción de relaciones.

En \cite{goudas2015argument} las UDAs son analizadas a nivel de oración.
Se propone usar NB, \textit{random forest}, regresión logística y SVM 
para la clasificación en argumentativas o no. De las oraciones argumentativas,
se extraen las secciones con carga argumentativa mediante anotación de etiquetas 
BIO con un campo condicional aleatorio (CRF, en inglés). Se predicen las relaciones como un 
problema de clasificación de pares de UDAs en donde emplean SVM. También
utilizan atributos escogidos a mano mediante conocimiento experto para la representación de 
las oraciones y palabras.

% \begin{itemize}
% 	\item Se analizan las UDAs a nivel de oraciones.
% 	\item Propone usar NB, \textit{random forest}, regresión logística y SVM 
% 	para la clasificación en argumentativas o no.
% 	\item En las oraciones argumentativas, se extraen las secciones con carga argumentativa 
% 	mediante anotación de etiquetas BIO con un campo condicional aleatorio (CRF, en inglés).
% 	\item Se predicen las relaciones como un problema de clasificación de pares de UDAs en donde emplean
% 	SVM. 
% 	\item Utilizan atributos escogidos a mano mediante conocimiento experto para la representación de 
% 	las oraciones y palabras.
% \end{itemize}

% \cite{goudas2015argument} al igual que \cite{palau2009argumentation} clasifica a las oraciones como
% argumentativas o no, mediante diferentes clasificadores como NB, \textit{Random Forest}, Regresión
% Logística y SVM. Sin embargo, \cite{goudas2015argument} aumenta la grandularidad de la segmentación al permitir
% la extracción de los segmentos que contienen la carga argumentativa de dentro de las oraciones previamente clasificadas
% como tal, esto se realiza mediante la extracción de etiquetas BIO de las oraciones con el uso de un 
% CRF. La predicción de las relaciones es modelado como un problema de clasificación
% usando SVM para clasificar pares de UDAs en relacionados o no. Atributos creados a mano 
% son usados en la extracción de UDAs; entre estos están posición de la oración en el texto, cantidad de verbos, comas, adverbios,
% palabras, entidades en la oración, también se emplean listas que guardan entidades relacionadas con el dominio 
% específico y palabras clave indicadoras de frases argumentativas. 

En \cite{stab2017parsing} las UDAs son extraídas mediante un modelo CRF con clasificación en etiquetas BIO.
La predicción y clasificación de relaciones se modela conjuntamente mediante dos SVMs,
optimizando la estructura final con un problema de optimización lineal en enteros. Los \textit{tokens}
y las UDAs están representados por vectores con atributos seleccionados por expertos.

% \begin{itemize}
% 	\item Se extraen las UDAs mediante un modelo CRF con clasificación en etiquetas BIO.
% 	\item La predicción y clasificación de relaciones se modela conjuntamente mediante dos SVMs,
% 	optimizando la estructura final con un problema de Optimización Lineal Entero.
% 	\item Las representaciones vectoriales de los \textit{tokens} y las UDAs se constituyen por atributos 
% 	seleccionados a mano por conocimiento experto.
% \end{itemize}

% \cite{stab2017parsing} proponen un mecanismo de segmentación basado en CRF. La clasificación
% y predicción de relaciones se modela conjuntamente con dos clasificadores SVM y un problema
% de Optimización Lineal Entero que encuentra la mejor estructura y asegura una disposición arbórea. En la segmentación
% de las UDAs, se extraen por cada \textit{token} su posición en el texto, si precede o sucede a un signo de puntuación, su parte de
% la oración, la probabilidad de que sea el comienzo de una UDA dado sus \textit{tokens} anteriores, entre otros. Para la extracción
% y clasificación de relaciones se proponen otros conjuntos de atributos como la cantidad de sustantivos comunes entre
% las componentes fuente y el objetivo, la presencia de indicadores argumentativos, representaciones vectoriales de \textit{tokens} 
% entre otros.

En \cite{eger2017neural} se presentan enfoques \textit{end-to-end}, modelando el problema como
uno de anotación secuencia a secuencia (capa de clasificación CRF al final), también
como uno de análisis sintáctico de dependencia (\textit{dependency parsing}) \cite{kiperwasser2016simple}
y además mediante el reconocimiento de entidades nombradas, en donde las entidades son las UDAs.
Las representaciones de los \textit{tokens} son aprendidas por el algoritmo mediante la 
aplicación de capas de CNN sobre los caracteres.

% \begin{itemize}
% 	\item Presenta un enfoques \textit{end-to-end}, modelando el problema como:
% 	\begin{itemize}
% 		\item Anotación secuencia a secuencia (capa de clasificación CRF al final).
% 		\item Análisis sintáctico de dependencia (\textit{dependency parsing}) \cite{kiperwasser2016simple}.
% 		\item Reconocimiento de entidades nombradas, en donde las entidades son las UDAs.
% 	\end{itemize}
% 	\item Las representaciones de los \textit{tokens} son aprendidas por el algoritmo mediante la 
% 	aplicación de capas de CNN sobre los caracteres.
% \end{itemize}

% En \cite{eger2017neural} trabajan el problema de EA como uno \textit{end-to-end}. 
% Para esto presentaron varias propuestas, entre ellas se encontraba
% modelar el problema como uno de secuencia a secuencia, usando RNN como 
% LSTM en versiones bidireccionales capturando información desde ambos lados de la secuencia.
% Para la representación de las palabras se extrajo información morfológica de las palabras mediante 
% la aplicación de una CNN a los caracteres de estas,
% al final, realizan la clasificación de la secuencia con un CRF. 
% Realizaron experimentos al modelar el problema como uno de \textit{Dependency Parsing} \cite{kiperwasser2016simple}. Este problema
% consiste en construir un árbol de dependencia que codifique las estructuras argumentativas. En este 
% se tiene que decidir entre varias opciones (\textit{shift}, \textit{reduce}) en dependencia del contenido de la pila y del \textit{buffer}
% para la confección del árbol.
% El problema fue modelado también como un problema de reconocimiento de entidades nombradas, en donde las entidades son las UDAs.

En \cite{dykes2020reconstructing} proponen métodos sobre reglas basadas en anotaciones lingüísticas (partes de la oración, lemas de palabras, etc.) 
para la extracción de argumentos. Dada las reglas creadas y el tipo
de datos con que se trabaja (cadenas de texto pequeñas); estos algoritmos tienden a tener una alta precisión aunque 
bajo recobrado, esto no es un gran problema en conjuntos de datos grandes, pero en conjuntos de menor tamaño o estructura 
más compleja pierden efectividad.

% \begin{itemize}
% 	\item Se proponen métodos sobre reglas basadas en anotaciones lingüísticas (partes de la oración, lemas de palabras, etc.) 
% 	para la extracción de argumentos. 
% \end{itemize}

% En \cite{dykes2020reconstructing} se proponen métodos basados en reglas para la extracción de argumentos sobre
% textos en Twitter. Estos métodos se centran en la confección de reglas basadas en anotaciones lingüísticas como
% partes de la oración y lemas de palabras. La recuperación está basada en los esquemas argumentativos comunes presentes
% en los textos. Dada las reglas creadas y el tipo
% de datos con que se trabaja, o sea, cadenas de texto pequeñas; estos algoritmos tienden a tener una alta precisión aunque 
% bajo recobrado, esto no es un gran problema en conjuntos de datos grandes, pero en conjuntos de menor tamaño o estructura 
% más compleja pierden efectividad.

En \cite{galassi2021deep} se propone el uso de redes residuales y mecanismos de atención
para la clasificación de UDAs y la predicción y clasificación de los enlaces. En este
se clasifica conjuntamente el tipo de UDA y la relación entre estas. Los textos son 
representados como una secuencia de vectores GloVe para los \textit{tokens}, por lo que 
no interviene conocimiento experto en la representación.

% \begin{itemize}
% 	\item Propone el uso de redes residuales y mecanismos de atención.
% 	\item Clasifica conjuntamente el tipo de UDA y la relación entre estas.
% 	\item Representa el texto como una secuencia de vectores GloVe para los \textit{tokens}.
% \end{itemize}

% \cite{galassi2021deep} propone el uso de redes residuales y mecanismos de atención
% para la creación de un modelo que, conjuntamente, clasifica el tipo de UDA y la relación existente entre estas.
% Este trabajo define el concepto de distancia argumentativa, añadiéndolo como característica y asume que las UDAs ya fueron 
% extraídas. En este caso, además de la distancia argumentativa, las secuencias son representadas 
% vectorialmente con GloVe.

Cada enfoque tiene su ventaja y desvantaja, el modelado secuencial de los problemas, introduce
una propagación de error en las etapas posteriores e impide que el modelo obtenga toda la información de
la fuente original. Para la obtención de reglas y atributos creados por expertos 
se necesita una cantidad 
de tiempo y recursos, y puede ser más difícil de escalar y mantener que representaciones aprendidas
automáticamente en el proceso de entrenamiento, estas se pueden moldear a los distintos
tipos de situaciones y esquemas presentes en los datos.

En los modelos propuestos (ver secciones \ref{ssec:segm_clsf_uda} y \ref{ssec:pred_clsf_enlaces}), gran parte de las representaciones son aprendidas en el proceso de 
entrenamiento y las que se agregan de forma manual casi no influyen en la escalabilidad del sistema.
Dado que se tienen dos modelos independientes se tiene una propagación del error al unir los resultados 
del primero con el segundo, aunque se hace uso del modelado conjunto de problemas para evitar esta 
situación en las tareas de extracción y clasificación de UDAs y extracción y clasificación de relaciones.

% En resumen, se contemplan disímiles enfoques al problema de EA desde una perspectiva enmarcada en modelos 
% simbólicos, estadísticos y neuronales en versiones tanto secuenciales como \textit{end-to-end}. 
% Cada uno de estos modelos presentan sus ventajas y desventajas a la hora de construirlos, 
% extenderlos y comprender su funcionamiento. En modelos simbólicos se presenta una alta
% precisión en dominios específicos debido a que se construyen teniendo en cuenta reglas específicas a un
% contexto dado. Estos modelos son poco escalables y difíciles de mantener ya que sus reglas son construídas
% a mano y dicho proceso requiere de conocimiento experto y tiempo. Los modelos estadísticos 
% se caracterizan por usar conjuntos de atributos creados a mano, dichos atributos son difíciles
% de encontrar, calcular y pueden no poseer relevancia en otros contextos diferentes a los que fueron creados,
% además, la necesidad de conocimiento experto es necesaria para su confección. Los modelos neuronales poseen
% una mayor adaptabilidad, en estos la entrada puede ser codificada en una representación que es aprendida por
% el mismo algoritmo, permitiendo su uso en esquemas argumentativos con características diferentes. Los modelos simbólicos y 
% estadísticos poseen la ventaja de poder explicar el porqué de los resultados devueltos cosa que se vuelve casi
% imposible en modelos neuronales.

% Dado que la EA es un proceso en el cual se necesita pasar por varias tareas, estas deben de ser completadas
% de alguna forma. Una manera de completarlas es hacerla una a la vez, independiente una de otra y pasándole
% la salida de etapas anteriores a las etapas siguientes. Esta manera secuencial de realizar las 
% tareas es bastante simple y ayuda a la creación de modelos simples y con tareas bien definidas, aunque trae consigo 
% la propagación de los errores a través del proceso y el no aprovechamiento de las interrelaciones entre variables 
% computadas de procesos anteriores. También requiere de la construcción, entrenamiento y evaluación de varios modelos.
% En cambio un enfoque \textit{end-to-end} poseen la habilidad de modelar el problema 
% desde su inicio hasta su final de manera conjunta, mediante \textit{Multi-Task Learning} (MTL) se modelan
% las tareas de manera conjunta creando un solo modelo complejo con una propagación de error menor.

\subsection{Proyección de etiquetas} %% RESUMED

La EA no presenta una gran cantidad de datos anotados en español con los cuales se pueda realizar 
un entrenamiento, además de esto la gran mayoría de corpus existentes se encuentran en lenguajes como inglés o alemán.
Para desarrollar la EA en otros lenguajes, como el español, se han investigado diferentes variantes
para la construcción de conjuntos de datos, a partir de los conjuntos de datos ya existentes.

La proyección de etiquetas es un algoritmo donde se 
transfieren las etiquetas de un corpus anotado a nivel de \textit{tokens} en un lenguaje origen hacia su traducción en un
lenguaje objetivo. En \cite{eger2018cross} se propone un algoritmo de proyección a partir de las alineaciones de 
palabras. El proceso se divide en varias partes:

\begin{enumerate}
	\item Traducción automática de oraciones: proceso de
	traducir automáticamente texto de un lenguaje fuente a un lenguaje objetivo.
	\item Alineación de palabras: consiste en asignar las palabras del lenguaje fuente
	a sus equivalentes generadas en el lenguaje objetivo.
	\item Proyección de etiquetas: consiste en transformar las etiquetas de las palabras en la secuencia origen
	hacia las palabras de la secuencia destino tomando como datos las alineaciones entre estas.
\end{enumerate}

% A continuación se presentan un ejemplo\footnote{Extraído del corpus de \cite{stab2017parsing}.} del 
% procedimiento descrito. En estos se observa el proceso de alineación
% de los índices de los \textit{tokens} en inglés con sus respectivos \textit{tokens} en español, esta relación puede ser de 
% muchos a muchos y no necesariamente se conserva el orden de las palabras. Luego se observa el paso de 
% etiquetas del lenguaje fuente al objetivo basadas en la información de la alineación. 

% \begin{adjustwidth}{25pt}{25pt}
% 	Firstly$_0$ ,$_1$ people$_2$ normally$_3$ have$_4$ lots$_5$ of$_6$ things$_7$ to$_8$ do$_9$ .$_{10}$ \\\\
% 	En primer$_0$ lugar$_0$ ,$_1$ la gente$_2$ normalmente$_3$ tiene$_4$ muchas$_5$ cosas$_7$ que$_8$ hacer$_9$ .$_{10}$
% \end{adjustwidth}
% \text{}\newline
% \begin{adjustwidth}{25pt}{25pt}
% 	Firstly$_O$ ,$_O$ people$_B$ normally$_I$ have$_I$ lots$_I$ of$_I$ things$_I$ to$_I$ do$_I$ .$_O$ \\\\
% 	En$_O$ primer$_O$ lugar$_O$ ,$_O$ la$_O$ gente$_B$ normalmente$_I$ tiene$_I$ muchas$_I$ cosas$_I$ que$_I$ hacer$_I$ .$_O$
% \end{adjustwidth}


% \subsection{Traducción de oraciones}

% La Traducción Automática consiste en el proceso de usar inteligencia artificial para
% traducir texto de un lenguaje fuente a un lenguaje objetivo sin la intervención humana.
% En la actualidad, este campo ha dado un gran paso pasando de modelos estadísticos a modelos
% neuronales obteniendo traducciones de una alta calidad sin variar significativamente de la humana, 
% condición necesaria para una buena proyección \cite{eger2018cross}.

% Este primer paso de la proyección de corpus consiste en traducir todas las oraciones existentes 
% en el conjunto de datos hacia el lenguaje objetivo. 
% A continuación se muestra una oración en inglés y su traducción al español\footnote{Extraído del corpus de \cite{stab2017parsing}.}:

% \begin{adjustwidth}{25pt}{25pt}
% 	Firstly , people normally have lots of things to do . \\
% 	En primer lugar , la gente normalmente tiene muchas cosas que hacer .
% \end{adjustwidth}

% \subsection{Alineación de palabras}

% La alineación de palabras consiste en encontrar las palabras generadas en el lenguaje objetivo por las 
% palabras en el lenguaje fuente.
% Algoritmos basado en modelos bayesianos, como FastAlign \cite{dyer2013fastalign}, 
% y Cadenas de Markov-Monte Carlo, como EFEMARAL \cite{ostling2016efficient} se ubican entre
% las primeras herramientas para la solución del problema. 
% Modelos más recientes se han enfocado en explotar las representaciones
% vectoriales de palabras y el uso de métodos de atención para la extracción de las
% alineaciones \cite{dou2021word}. Algunas consideraciones sobre el proceso: las relaciones 
% formadas entre palabras pueden ser de tipo muchos a muchos, además de no tener el mismo orden de la 
% oración inicial o incluso no estar relacionadas directamente con una palabra en la oración objetivo.
% Estas consideraciones dan una medida de la dificultad de la tarea en cuestión.
% En el ejemplo siguiente se observa el resultado de las herramientas de alineación, en este 
% las palabras en el idioma de origen (inglés) están anotadas con su posición en la oración y 
% las palabras en el idioma objetivo (español) están anotadas con la posición de la palabra que 
% la originó en el idioma origen:

% \begin{adjustwidth}{25pt}{25pt}
% 	Firstly$_0$ ,$_1$ people$_2$ normally$_3$ have$_4$ lots$_5$ of$_6$ things$_7$ to$_8$ do$_9$ .$_{10}$ \\
% 	En primer$_0$ lugar$_0$ ,$_1$ la gente$_2$ normalmente$_3$ tiene$_4$ muchas$_5$ cosas$_7$ que$_8$ hacer$_9$ .$_{10}$
% \end{adjustwidth}
% \begin{adjustwidth}{25pt}{25pt}
% 	Firstly$_O$ ,$_O$ people$_B$ normally$_I$ have$_I$ lots$_I$ of$_I$ things$_I$ to$_I$ do$_I$ .$_O$ \\
% 	En$_O$ primer$_O$ lugar$_O$ ,$_O$ la$_O$ gente$_B$ normalmente$_I$ tiene$_I$ muchas$_I$ cosas$_I$ que$_I$ hacer$_I$ .$_O$
% \end{adjustwidth}


% \subsection{Proyección de etiquetas}

% La proyección de etiquetas consiste en transportar las etiquetas de las palabras en la secuencia origen
% hacia las palabras de la secuencia destino tomando como datos las alineaciones entre estas. En \cite{yarowsky2001inducing}
% se trata el problema de proyección de frases nominales, estas frases tienen como característica que son resistentes
% a ser divididas en caso de ser traducidas, y aunque evidencian 
% cambios en el orden de las palabras, mantienen la misma ventana; dicha propiedad se cumple para las UDAs también.
% La proyección de UDAs es más simple en dado
% que solamente se tiene en cuenta la ventana y las etiquetas en estas son constantes, no pasa con la proyección en
% frases nominales, las cuales pueden cambiar dentro de una ventana, por lo que algoritmos más simples existen
% para esta tarea \cite{eger2018cross}. En el ejemplo de proyección están anotadas las etiquetas originales en formato BIO
% de las palabras de la oración en el lenguaje origen (inglés) y se muestra el
% resultado de proyectar estas al lenguaje objetivo utilizando los resultados de la alineación de palabras:

% \begin{adjustwidth}{25pt}{25pt}
% 	Firstly$_O$ ,$_O$ people$_B$ normally$_I$ have$_I$ lots$_I$ of$_I$ things$_I$ to$_I$ do$_I$ .$_O$ \\
% 	En$_O$ primer$_O$ lugar$_O$ ,$_O$ la$_O$ gente$_B$ normalmente$_I$ tiene$_I$ muchas$_I$ cosas$_I$ que$_I$ hacer$_I$ .$_O$
% \end{adjustwidth}

\section{Segmentación y clasificación de UDAs}

Las tareas de segmentación y clasificación de UDAs se resuelven conjuntamente. Para esto se modela 
como un problema secuencia a secuencia cuyo objetivo es asignar, a los \textit{tokens} extraídos del documento 
entrada, una etiqueta BIOES para segmentar las UDAs. Para la clasificación del tipo 
de UDA, al conjunto de etiquetas BIES se le añade otra etiqueta que representa el tipo de UDA. Con 
este esquema se obtiene una cantidad de etiquetas $|\{B,I,E,S\}| \cdot |Clasificaciones \, de \, UDA| + |\{O\}|$.

% Esta primera parte se modela como un problema secuencia a secuencia cuyo objetivo es asignar a los \textit{tokens} 
% extraídos del documento entrada una etiqueta BIOES para segmentar las UDAs. Para la clasificación del tipo 
% de UDA, al conjunto de etiquetas BIES se le añadieron las clasificaciones que presenta el corpus entrenante.
% En el siguiente ejemplo se muestra una salida del modelo presentando las clasificaciones de
% $A$ como argumento y $P$ como premisa:

% \begin{adjustwidth}{25pt}{25pt}
% 	En$_O$ primer$_O$ lugar$_O$ ,$_O$
% 	[\textit{el$_{B-A}$}
% 	\textit{correo$_{I-A}$}
% 	\textit{electrónico$_{I-A}$}
% 	\textit{puede$_{I-A}$}
% 	\textit{contar$_{I-A}$}
% 	\textit{como$_{I-A}$}
% 	\textit{uno$_{I-A}$}
% 	\textit{de$_{I-A}$}
% 	\textit{los$_{I-A}$}
% 	\textit{resultados$_{I-A}$}
% 	\textit{más$_{I-A}$}
% 	\textit{beneficiosos$_{I-A}$}
% 	\textit{de$_{I-A}$}
% 	\textit{la$_{I-A}$}
% 	\textit{tecnología$_{I-A}$}
% 	\textit{moderna$_{E-A}$}]
% 	.$_{O}$
% 	[\textit{Años$_{B-P}$}
% 	\textit{atrás$_{I-P}$}
% 	\textit{,$_{I-P}$}
% 	\textit{las$_{I-P}$}
% 	\textit{personas$_{I-P}$}
% 	\textit{pagaban$_{I-P}$}
% 	\textit{gran$_{I-P}$}
% 	\textit{cantidad$_{I-P}$}
% 	\textit{de$_{I-P}$}
% 	\textit{dinero$_{I-P}$}
% 	\textit{para$_{I-P}$}
% 	\textit{enviar$_{I-P}$}
% 	\textit{sus$_{I-P}$}
% 	\textit{cartas$_{I-P}$}
% 	\textit{y$_{I-P}$}
% 	\textit{sus$_{I-P}$}
% 	\textit{pagos$_{I-P}$}
% 	\textit{estaban$_{I-P}$}
% 	\textit{sujetos$_{I-P}$}
% 	\textit{al$_{I-P}$}
% 	\textit{peso$_{I-P}$}
% 	\textit{de$_{I-P}$}
% 	\textit{sus$_{I-P}$}
% 	\textit{cartas$_{I-P}$}
% 	\textit{o$_{I-P}$}
% 	\textit{paquetes$_{I-P}$}
% 	\textit{y$_{I-P}$}
% 	\textit{muchos$_{I-P}$}
% 	\textit{accidentes$_{I-P}$}
% 	\textit{podrían$_{I-P}$}
% 	\textit{causar$_{I-P}$}
% 	\textit{problemas$_{I-P}$}
% 	\textit{que$_{I-P}$}
% 	\textit{causarían$_{I-P}$}
% 	\textit{que$_{I-P}$}
% 	\textit{el$_{I-P}$}
% 	\textit{correo$_{I-P}$}
% 	\textit{no$_{I-P}$}
% 	\textit{fuera$_{I-P}$}
% 	\textit{enviado$_{E-P}$}]
% 	.$_{O}$
% \end{adjustwidth}

\subsection{Modelo de segmentación y clasificación de UDAs}\label{ssec:segm_clsf_uda}

Sea $D$ un documento entrada, este es separado en una secuencia de $n$ \textit{tokens} $D_i$, donde $n$ es la mayor longitud encontrada
en los documentos del conjunto de datos (si la cantidad de \textit{tokens} es menor que $n$ entonces $D_i$ es completado con un \textit{token} especial de enmascarado). 
A cada \textit{token} se le asigna
su representación vectorial GloVe de dimensión $g=300$, dando como resultado $G_{ij} \in \mathbb{R}^{n \times g}$.
Esta representación inicial presenta información semántica de las palabras y conserva las relaciones 
espaciales entre ellas. 

Para la representación de información morfológica de la palabra se construyen dos
codificadores que procesan los caracteres de cada \textit{token} y devuelven una representación vectorial de estos.
A cada caracter se le asigna un vector que será entrenado convirtiendo un \textit{token} en un vector de dimensión
$q \times c$, donde $q$ es el tamaño máximo de palabra en el conjunto de datos y $c$ es la dimensión del vector
asignado a cada caracter.

Uno de los modelos entrenados está basado en CNN, este modelo entrena una representación de caracteres de dimensión
$cd=50$, representando un \textit{token} como un vector de dimensión $q \times cd$. Se conforma por una capa de convolución unidimensional
con $f=30$ filtros y un kernel de tamaño $k=3$, seguida por una capa \textit{max pooling} que convierte la secuencia en un vector
de dimensión $1 \times f$, que luego es concatenado a la representación del \textit{token} a que pertenece.

Otro modelo utilizado para calcular una representación morfológica está basado en RNN. Se usó
un modelo LSTM bidireccional con dimensión $l=25$ para calcular la representación del \textit{token}, para las dimensiones de los caracteres se
utilizaron vectores de tamaño $l$, el resultado final constituye la concatenación de la corrida hacia adelante y
hacia atrás, formando una representación de dimensión $1 \times 2 \cdot l$ del \textit{token}. Este vector es concatenado a la representación
del \textit{token} correspondiente. 

Otro atributo usado en la representación de los \textit{tokens} constituyen las etiquetas de 
partes de la oración de estos.
El conjunto de etiquetas elegido es un conjunto universal \cite{petrov2011universal} aplicable a muchos idiomas.
Estas etiquetas se representan como un vector al que se le asigna 1 en la posición correspondiente a la clase y 0 en 
los otros elementos (codificación \textit{one-hot}) y este es transformado por una capa densa con $p=5$ neuronas
y función de activación \textit{ReLU}. El resultado se concatena a la representación del \textit{token} correspondiente. Mediante 
la extracción de estos atributos el \textit{token} es representado en tres maneras: semántica, morfológica y estructural, con el 
objetivo de que sean aprendidos los rasgos lingüísticos correspondientes.

Del proceso de vectorización se obtiene un vector con dimensión $n \times t$, donde $t$ es la dimensión final de la representación
de los \textit{tokens}  Este vector es modificado por una capa LSTM bidireccional de dimensión $m=200$. A esta salida se le 
añade una conexión residual al ajustarle la dimensión con una capa densa. Luego, la secuencia es procesada por una 
capa densa de dimensión $k=100$ con activación \textit{ReLU}, produciendo una representación final de dimensión 
$n \times k$. Finalmente, se utiliza una capa CRF
para la clasificación final de la secuencia en las etiquetas finales. El resultado final constituye un vector
de dimensión $n$ que representa las clasificaciones inferidas por el modelo (Figura \ref{fig:segmenter_model}).

Para prevenir el sobreajuste se agregaron capas de normalización y de \textit{dropout} (0.5) entre cada proceso y se usaron regularizaciones
L2 y \textit{dropout} en las capas densas y LSTM. 
Para prevenir el sobreentrenamiento se aplicó una 
terminación temprana cuando no se encontró una mejora de la función de pérdida en el conjunto de validación
por más de 10 épocas consecutivas. Como optimizador se utilizó Adam con una tasa de aprendizaje de $0.001$.

La salida del modelo es procesada para eliminar los errores en las etiquetas BIOES, errores como segmentos 
que no empiecen en B o terminen en E, o segmentos con más de una clasificación, 
obteniendo así un formato BIOES válido.

% \subsection{Posprocesamiento de segmentación y clasificación de UDAs}

% La salida del modelo constituye una secuencia de etiquetas en formato BIOES. Esta está propensa
% a contener errores en su formato, por ejemplo, secuencias no terminadas en E, segmentos continuos con más de una 
% meta-etiqueta, entre otros.
% Para la corrección de la estructura se propone el siguiente algoritmo con dos partes. La primera
% consiste en arreglar la estructura BIOES, para esto se mantiene una ventana de tamaño
% 3, [\_ , \_ , \_], sobre la secuencia y se asume que la parte anterior a la posición de la ventana no presenta errores. Al encontrar una
% ventana inválida se necesita observar la siguiente ventana para poder decidir cómo se arregla el error, ya que se
% podría dar el caso que se observe [O, O, I] y la próxima sea [O, I, O], en donde solamente viendo la primera ventana no se podría saber si el cambio 
% correcto corresponde a sustituir I por B o por S. Una vez observadas las dos ventanas, se procede a realizar el 
% arreglo correspondiente. En casos donde sea ambigua la manera de arreglar la ventana, [I, I, O] por ejemplo
% (La I o la O pueden ser 
% sustituidas por una E), se utiliza una función que recibe un segmento y devuelve la gravedad del error.
% El error con mayor gravedad será arreglado, en caso de ser iguales se arreglará la etiqueta más a la izquierda.
% Este procedimiento devuelve una secuencia BIOES correctamente anotada, debido a que a partir de una secuencia sin 
% errores en cada paso se va arreglando la ventana y una vez esta llega al final arregló todos los elementos de la secuencia.
% Una vez la secuencia tiene la estructura BIOES correctamente anotada el problema
% consiste en arreglar las meta-etiquetas, ya que una misma secuencia BIOES pudo haber sido anotada con diferentes
% tipos, en este caso se toma la etiqueta más representativa del segmento continuo.

\begin{figure}[h]
	\centering
	\includesvg[width=7cm]{Graphics/Modelo_Segmenter_UDA_No_Opcional.svg}
	\caption{Segmentador de UDAs.}
	\label{fig:segmenter_model}
\end{figure}

\section{Predicción y clasificación de enlaces}

% Las tareas de segmentación y clasificación de UDAs se resuelven conjuntamente. Para esto se modela 
% como un problema secuencia a secuencia cuyo objetivo es asignar, a los \textit{tokens} extraídos del documento 
% entrada, una etiqueta BIOES para segmentar las UDAs. Para la clasificación del tipo 
% de UDA, al conjunto de etiquetas BIES se le añade otra etiqueta que representa el tipo de UDA. Con 
% este esquema se obtiene una cantidad de etiquetas $|\{B,I,E,S\}| \cdot |Clasificaciones \, de \, UDA| + |\{O\}|$
	
Las tareas de extracción y clasificación de enlaces son modeladas de forma conjunta.
El problema consiste en clasificar pares de UDAs, representando origen y objetivo del enlace, 
en el tipo de relación que existen entre estas.
Como tarea auxiliar se clasifican los tipos de UDAs que intervienen en la relación. La salida 
del modelo constituye en una tupla de tres elementos: la clasificación de la relación, 
la clasificación de la UDA origen, la clasificación de la UDA objetivo. Si el enlace
existe o no, es calculado a partir del vector de probabilidades obtenido de la clasificación de la relación.

\subsection{Modelo de predicción y clasificación de enlaces}\label{ssec:pred_clsf_enlaces}

Sean dos UDAs, $S$ y $T$, donde $S$ representa la fuente de la relación, mientras que $T$ representa
al objetivo. Estas secuencias son tokenizadas y se les asigna la representación GloVe de cada palabra, obteniendo
dos vectores de dimensión $u \times g$, donde $u$ es el tamaño máximo de UDAs en el conjunto de entrenamiento
y $g=300$ es la dimensión del \textit{embedding}.

Estos vectores son modificados por una red densa compuesta por $ca = 4$ capas con activación \textit{ReLu}
de dimensiones $50$, $50$, $50$ y $300$ respectivamente, añadiendo una conexión residual a la salida de esta. 
El próximo paso consiste en aplicar una capa densa de dimensión $di=50$ y luego un \textit{average pooling}
de tamaño $dp=10$, obteniendo vectores de dimensión $\frac{q}{dp} \times di$. 
Estos vectores son modificados por un LSTM bidireccional con $lm=50$ unidades. 

% Un módulo de atención es aplicado 
% sobre los vectores fuentes, 
% en este actúan como consultas el promedio de los vectores objetivo y como llaves y valores los vectores fuentes,
% el procedimiento simétrico es realizado para los vectores objetivos.
La salida de los procesamientos es concatenada con la distancia argumentativa, obteniendo una representación 
conjunta de la relación a analizar. Esta representación es modificada por una red residual obteniendo
una representación final de dimensión $l=20$ y luego sometida a los clasificadores de relación y de tipos de UDAs
(Figuras \ref{fig:link_predictor_model1} y \ref{fig:link_predictor_model2}).

Para prevenir el sobreajuste se agregaron capas de normalización y de \textit{dropout} entre cada 
proceso y se usaron regularizaciones L2 y \textit{dropout} en las capas densas y LSTM, 
todos los \textit{dropout} tienen valor $dr=0,1$. Para prevenir el sobreentrenamiento se aplicó una 
terminación temprana cuando no se encontró una mejora de la función de pérdida en el 
conjunto de validación durante $v=5$ épocas consecutivas. Como optimizador se utilizó el algoritmo de Adam con descenso 
exponencial y tasa de aprendizaje $lr=0.003$.

Dado que se realiza un aprendizaje de varias tareas, se tienen varias funciones de pérdida individuales que conforman 
la función de pérdida final $e$. Sea $e_r$ la función de pérdida de la clasificación de la relación, $e_s$ la del tipo de UDA origen  
y $e_t$ del tipo de UDA objetivo, entonces $e = 10 \cdot e_r + e_s + e_t$ \cite{galassi2021deep}.

\subsection{Preprocesamiento de predicción y clasificación de enlaces}

El uso de este modelo se concreta a nivel de documento, en donde ya se tienen las UDAs extraídas. Para alimentar
al modelo con los pares de UDAs y sus distancias argumentativas se seleccionan todos los pares de estos que cumplan
que no se enlacen con ellos mismos, por ejemplo, $a \rightarrow a$; y que su distancia argumentativa absoluta ($da$) sea menor 
que $10$. Estas restricciones disminuyen el número de pares extraídos por documentos a una cantidad lineal 
con respecto a la cantidad de UDAs presentes, ya que por cada UDA solamente se tomarían $2 \cdot da$ elementos como máximo
(los que la preceden y los que la suceden). 

Además de las etiquetas originales del conjunto de entrenamiento, se añaden elementos extras a este
conjunto. Estos elementos son las representaciones inversas de las relaciones, por ejemplo, si $a \xrightarrow{c} b$ entonces 
se agregará el par $b \xrightarrow{c^{-1}} a$, donde $c^{-1}$ es una nueva clasificación de relación que representa
el inverso de la clasificación $c$. Este proceso se realiza para aumentar la cantidad de relaciones positivas en el
conjunto entrenante, ya que, aun con las reducciones hechas, existe un desbalance de clases positivas y negativas en
las relaciones.

\subsection{Posprocesamiento de predicción y clasificación de enlaces}

Se calcula una salida extra a partir de las distribuciones de probabilidad de las relaciones 
devueltas por el modelo, esta salida representa si el par está enlazado o no directamente. Para este cálculo se 
suman las categorías vinculadas a las clases originales del conjunto de datos, esta se toma como la probabilidad de estar 
enlazados, que en caso de ser mayor del 50\%, se devuelve verdadero. Para dar el resultado final se eliminan del 
conjunto de respuesta las relaciones anotadas con las etiquetas inversas añadidas en el paso de preprocesamiento 
y son devueltas aquellas que se clasifiquen como enlazadas según el criterio anterior.

\begin{figure}[h]
	\centering
	\includesvg[width=7cm]{Graphics/Modelo_Link_Prediction_No_Atencion1.svg}
	\caption{Predictor de enlaces.}
	\label{fig:link_predictor_model1}
\end{figure}
\begin{figure}[h]
	\centering
	\includesvg[width=7cm]{Graphics/Modelo_Link_Prediction2.svg}
	\caption{Predictor de enlaces (continuación).}
	\label{fig:link_predictor_model2}
\end{figure}

\section{Conjuntos de Datos}

Para el entrenamiento de los modelos propuestos se utilizaron corpus diferentes, estos
presentan esquemas de anotación distintos entre sí, difiriendo principalmente en la definición de UDA y 
las clasificaciones dadas a estas y a las relaciones.

Todos los conjuntos de datos están originalmente en inglés, por lo tanto, se les aplicó el algoritmo de proyección
de corpus para obtener uno en español para ser usado en el entrenamiento de los modelos.

Para la traducción automática se utilizó el servicio de Google Translate, 
para obtener las alineaciones de palabras se probaron dos algoritmos: FastAlign \cite{dyer2013fastalign} y AwesomeAlign 
\cite{dou2021word}, siendo este último el seleccionado, finalmente la proyección de etiquetas
fue llevada a cabo por el algoritmo propuesto en \cite{eger2018cross}.

% A todos los conjuntos se les proyectó al lenguaje 
% español y se les realizó un aumento de datos. Para la proyección se utilizó 
% Como conjunto para la validación fueron usadas 
% una parte de las Cartas a la Dirección del periódico \textit{Granma}.

\subsection{Corpus Ensayos Argumentativos}\label{corpus:persuasive_essays}

Este corpus \cite{stab2017parsing} presenta 402 documentos, divididos por los autores en 286 documentos para entrenamiento (70\%), 
80 para prueba (20\%) y 36 para validación (10\%). El corpus contiene ensayos de estudiantes en los que 
se argumentan sobre temas como cooperar o competir y sobre las contribuciones de la tecnología a la sociedad.
Las anotaciones de las UDAs se conforman por segmentos de textos argumentativos,
clasificados en \textit{MajorClaim} con 751 (12\%), \textit{Claim} con 1506 (25\%) y \textit{Premise} con 3832 (63\%).

La estructura de las relaciones entre las UDAs conforman árboles en los que se tienen como raíz las 
\textit{MajorClaim} del texto. Las relaciones solo están permitidas entre \textit{Premise-Premise} y \textit{Premise-Claim}, clasificadas
en \textit{attack} con 219 (6\%) y \textit{support} con 3613 (93\%). Las relaciones entre \textit{Claim} y \textit{MajorClaim} son anotadas 
de manera diferente, para 
darle a las \textit{Claim} una clasificación de si está a favor (1228) o en contra (278) de las \textit{MajorClaim} del documento,
estas anotaciones fueron convertidas a relaciones de \textit{attack} y \textit{support} respectivamente. El número final con la inclusión de estas aumenta a 715 (10\%) de ataque y 
5958 (90\%) de apoyo.

\subsection{CDCP}\label{corpus:cdcp}

El corpus CDCP \cite{niculae2017argument} está conformado por 731 comentarios de usuarios extraídos de la web sobre el tema de 
prácticas de cobro de deudas a los consumidores.
Las UDAs se encuentran segmentadas en oraciones y todas se consideran argumentativas.
Están clasificadas en 
\textit{policy} con 815 (17\%), \textit{value} con 2180 (44\%), \textit{fact} con 
785 (16\%), \textit{testimony} con 1116 (22\%) y \textit{reference} con 32 (1\%). 
Las relaciones se encuentran clasificadas en \textit{reason} con 1352 (95\%) y \textit{evidence} con 73 (5\%).

\subsection{AbsTRCT}

El corpus AbsTRCT \cite{mayer2020transformer} se compone de 500 documentos sobre el estudio de cuatro enfermedades diferentes:
glaucoma, hipertensión, hepatitis B y diabetes. Cada oración es una UDA, aunque no todas son consideradas
argumentativas. Estas se clasifican en \textit{MajorClaim} con 93 (3\%), \textit{Claim} con 993 (30\%) y \textit{Premise} con 2198 (67\%).
Las relaciones están representadas por tres categorías: \textit{support} con 1763 (85\%), \textit{partial-attack} con 238 (12\%) y
\textit{attack} con 60 (3\%).

En resumen, estos datos no son numerosos como para realizar el entrenamiento de un modelo de aprendizaje automático
y presentan un gran desbalance en sus clases.
En la Tabla \ref{table:corpus_info} se muestran los datos promedio de la composición de los diferentes corpus. 
Se observa una composición heterogénea entre estos, principalmente el CDCP difiere mucho de los demás.

\begin{table}[h]
	\begin{center}
		\scalebox{0.8}{
		\begin{tabular}{|p{20mm}|c|c|c|c|} 
			\hline\rule{-2pt}{15pt}
			{\bf Corpus}                 & {\bf Ensayos} 		& {\bf CDCP } 	   & {\bf AbsTRCT}  \\
										 & {\bf Argumen-} 		& 				   & 			    \\
										 & {\bf tativos} 		& 				   & 			    \\
			\hline\rule{-4pt}{10pt}
			\textit{Tokens}  	   		   	     & 381 	   			    & 127              & 371            \\
			\textit{Tokens} Argu- 	   		   	 &     	   			    & 	               & 	            \\
			mentativos	 		   	     & 68\%			    	& 99\%             & 50\%           \\
			UDAs                   	     & 35\%    			    & 97\%             & 47\%           \\
			Relaciones		     	     & 	    			    & 	               &	            \\ 
			por UDA     	     		 & 1,08    			    & 0,30             & 0,63           \\ 
			\hline
		\end{tabular}
		}
	\end{center}
	\caption{\label{table:corpus_info}Información de promedios de los conjuntos de datos.}
\end{table}

% \subsection{Creación de corpus en español}

% \subsubsection{Aumento de datos}

% A los conjuntos de datos a analizar se les realizó un aumento de datos mediante la técnica de \textit{backtranslation},
% aplicándole la proyección de etiquetas de los elementos originales a los aumentados.
% Esto contribuyó a duplicar la cantidad de elementos disponibles. Los resultados obtenidos al comparar los 
% elementos originales con los aumentados se reflejan en la Tabla \ref{table:data_augmentation}.
% Estos muestran que se logró una variación pequeña en los datos, aunque conservando la 
% longitud original del texto. 

% \begin{table}[h]
% 	\begin{center}
% 		\scalebox{0.7}{
% 		\begin{tabular}{|l|c|c|c|c|} 
% 			\hline\rule{-2pt}{15pt}
% 			{\bf Corpus}                 & {\bf Ensayos} 		& {\bf CDCP} & {\bf AbsTRCT} \\ 
% 						                 & {\bf Argumentativos} & 		 	 & 	 			 \\ 
% 			\hline\rule{-4pt}{10pt}
% 			Jaccard 					 																				& 0.69    & 0.72          & 0.74	\\
% 			Levenshtein                  																				& 96	  & 30			  & 86		\\
% 			$\frac{|\mathrm{Palabras} \, \mathrm{originales}|}{|\mathrm{Palabras \, aumentadas}|}$                & 1.00    & 1.02          & 1.04	\\ 
% 			\hline
% 		\end{tabular}
% 		}
% 	\end{center}
% 	\caption{Datos promedios comparando los textos originales con los aumentados.}\label{table:data_augmentation}
% \end{table}

% \subsubsection{Proyección de corpus}

% Todos los conjuntos de datos están originalmente en inglés, por lo tanto, se les aplicó el algoritmo de proyección
% de corpus para obtener uno en español para ser usado en el entrenamiento de los modelos. 
% Para la traducción automática se utilizó el servicio de Google Translate\footnote{\url{https://translate.google.com/}}. 
% Para calcular las 
% alineaciones de palabras se probaron dos algoritmos: FastAlign \cite{dyer2013fastalign} y AwesomeAlign 
% \cite{dou2021word}. Se observó que el primero, aunque es más rápido posee una calidad menor en los resultados,
% el segundo posee una mayor calidad, aunque requiere de mayor tiempo y recursos para ejecutarse. Para los experimentos
% se usó finalmente AwesomeAlign. La proyección de las etiquetas fue llevada a cabo por el algoritmo propuesto 
% en \cite{eger2018cross}.

\subsection{Cartas a la Dirección}

La sección ``Cartas a la Dirección'' \cite{gallego2013cartas} es un segmento del periódico \textit{Granma} donde se publican
cartas enviadas por la población o empresas a dicha entidad. En general, las cartas 
presentan dudas o problemas de la población con el objetivo de obtener respuestas del organismo
asociado. 

Mediante \textit{crawling}, se extrajeron 2891 cartas desde el 30 de agosto del 2013 hasta el 28 de octubre del 2022. Estas 
contienen aproximadamente 975000 palabras en los datos y, en promedio, la cantidad de palabras por carta es 330.
Se encontraron 874 cartas en respuesta a cartas enviadas, lo que representa un 30\% del total. 

% Se extrajeron
% los comentarios asociados a las cartas, en este sentido 987 cartas no presentan comentarios y, en promedio, 
% se realizan 2 comentarios por carta. 
Los textos presentan un título y un formato relativamente libre, 
aunque en las cartas de respuesta se puede observar una firma de la persona que respondió y la entidad que 
representa. Del total de cartas, se seleccionaron las que fueran en respuesta a otra y también las 
cartas que fueron respondidas para tener una mayor concentración de cartas que fueran argumentativas, 
esta selección está conformada por 1702 cartas, lo que representa un 59\% del total de cartas.

% \section{Implementación}

% La implementación de los modelos y algoritmos de procesamiento y visualización de datos se encuentran en 
% un repositorio de GitHub\footnote{\url{https://github.com/luisoibarra/argument-mining}}. Esta implementación
% está concebida para que se pueda extender fácilmente para el uso con otros idiomas diferentes del inglés y el 
% español. Se basa en una arquitectura de procesamiento secuencial en el cual cada paso del proceso realiza
% una tarea específica y lo más desacoplada posible de las otras. Las tareas realizadas son:

% \begin{itemize}
% 	\item Creación del corpus en un formato estándar: dado que los corpus vienen en diferentes
% 	      formas, este paso se realiza para trabajar sobre una misma representación de este.
% 	\item Proyección del corpus de un lenguaje fuente a un lenguaje objetivo: en el caso de
% 	      uso del trabajo se proyecta del inglés al español.
% 	      \begin{itemize}
% 		      \item Traducción y alineación de oraciones.
% 		      \item Alineación de palabras.
% 		      \item Proyección de etiquetas.
% 	      \end{itemize}
% 	\item Extracción y clasificación de UDAs.
% 	\item Extracción y clasificación de las relaciones entre las UDAs.
% 	\item Visualización de los resultados.
% \end{itemize}

% \subsection{Herramientas}

% El lenguaje empleado para la confección del software fue Python \cite{python}, este presenta 
% una gran variedad de herramientas 
% para el trabajo con texto, visualización de datos y creación de modelos de aprendizaje profundo.
% Se utilizó tensorflow \cite{tensorflow} en su versión 2.9.2 para la construcción y entrenamiento de los modelos. 
% Para el procesamiento de los textos se utilizaron nltk \cite{nltk} y spacy \cite{spacy}, con estos se realizaron tareas
% como la extracción de \textit{tokens} y oraciones del texto, la anotación de las etiquetas de partes de la oración. Se utilizaron 
% ambos paquetes para el procesamiento debido a que, en dependencia de la situación, cada uno presenta diferentes
% ventajas. En el caso de nltk, presenta algoritmos rápidos para el procesamiento de texto que no 
% requieren de muchos recursos computacionales, sin embargo, estos algoritmos no están disponibles de inmediato
% para otros lenguajes como el español. Spacy por su parte presenta algoritmos más certeros a costo 
% de mayor tiempo de procesamiento y gasto de recursos computacionales, y también presenta una cantidad mayor de lenguajes 
% disponibles. Para la visualización y manejo de los datos, y cálculo de métricas se utilizaron 
% matplotlib \cite{matplotlib}, pandas \cite{pandas} y sklearn \cite{sklearn}. 
% Para la recolección de las Cartas a la Dirección del periódico \textit{Granma} se utilizó scrapy \cite{scrapy}.
% Como interfaz visual para el usuario se utilizó la herramienta Brat \cite{brat}
% (Figura \ref{fig:brat_persuasive_granma_letters}). Esta herramienta permite
% la visualización y edición de las estructuras argumentativas. Dado que Brat es una página web, esta se puede
% desplegar y permite su uso online.

% \begin{figure}[h]
% 	\centering
% 	% \includegraphics[scale=.4]{Graphics/persuasive_2019-01-25_informa-recursos-hidraulicos-sobre-abasto-de-agua-en-manzanillo_abasto-de-agua-en-manzanillo.png}
% 	\includegraphics[width=7cm]{Graphics/persuasive_2019-03-22_inconformidad-con-la-chequera.png}
% 	\caption{Visualización con Brat de las estructuras argumentativas.}
% 	\label{fig:brat_persuasive_granma_letters}
% \end{figure}

% \subsection{Formato Estándar}

% El formato estándar creado es basado en el esquema de anotación CoNLL, donde se anotan a nivel de \textit{token} todos los aspectos 
% relevantes para las tareas a realizar. La segmentación de las UDAs son representadas por las anotaciones 
% BIO o BIOES en cada palabra, en adición, las clasificaciones de estas son anotadas al adicionar el nombre 
% de esta separada por un guión. Las relaciones son anotadas auxiliándose de la distancia argumentativa, estas 
% son agregadas al anotar el tipo de relación con su respectiva distancia ambas separadas por un guión. A 
% continuación se muestran ejemplos de este formato, conformado por el \textit{token}, su clasificación BIOES, su clasificación
% UDA, y las relaciones representadas por su clasificación y su distancia argumentativa:

% \begin{itemize}
% 	\item Elemento fuera de una UDA: $an\text{á}lisis \quad O$
% 	\item UDA intermedia con una relación: $contribuye \quad I-Premise-attacks-5$
% 	\item Inicio de UDA con dos relaciones: $atletas \quad B-Claim-attacks--1-attacks-12$
% \end{itemize}

\section{Resultados}

Para realizar la selección del modelo se utilizó el corpus de Ensayos Argumentativos. Con este se ajustaron
las arquitecturas e hiperparámetros de los modelos propuestos. La mejor combinación de estos fue utilizada 
para el entrenamiento de los corpus restantes. Finalmente, los modelos fueron utilizados para anotar los 
textos de la sección ``Cartas a la Dirección'' de \textit{Granma}. 

% \subsection{Hardware}

% Gran parte del procesamiento se llevo a cabo en una computadora $i5$ con $8GB$ de RAM ampliada con $4GB$ de memoria 
% \textit{swap} \cite{swap}, aunque se requirió el uso de la plataforma Colab \cite{colab} para 
% el entrenamiento de algunos modelos por falta de recursos locales.

\subsection{Segmentador de UDA}

% En el entrenamiento del segmentador de UDA se hicieron variaciones en la arquitectura propuesta con respecto a la
% presencia o no de las siguientes componentes, presentando cuatro candidatos (Tabla \ref{table:segmenter_architecture_table}):

% \begin{itemize}
% 	\item Atributos de POS en la entrada del algoritmo (POS).
% 	\item Atributos extraídos por la CNN de la palabra (Char-CNN).
% 	\item Atributos extraídos por la LSTM bidireccional de la palabra (Char-LSTM).
% 	\item Conexiones residuales (Res).
% 	\item Capa densa final (Densa).
% 	\item Capas de normalizaciones (Norm).
% \end{itemize}

% \begin{table}[h]
% 	\begin{center}
% 		\begin{tabular}{|l|c|c|c|c|} 
% 			\hline\rule{-2pt}{15pt}
% 			{\bf Modelos}  & {\bf 1}     & {\bf 2}     & {\bf 3}     & {\bf 4}     \\ 
% 			\hline\rule{-4pt}{10pt}
% 			POS 	  & $\times$  & $\times$ 	 & $\checkmark$ & $\checkmark$ \\
% 			Char-CNN  & $\times$  & $\checkmark$ & $\checkmark$ & $\checkmark$ \\
% 			Char-LSTM & $\times$  & $\checkmark$ & $\checkmark$ & $\checkmark$ \\
% 			Residual  & $\times$  & $\checkmark$ & $\checkmark$ & $\checkmark$ \\
% 			Norm 	  & $\times$  & $\checkmark$ & $\checkmark$ & $\checkmark$ \\
% 			Densa 	  & $\times$  & $\times$ 	 & $\times$ 	& $\checkmark$ \\
% 			\hline
% 		\end{tabular}
% 	\end{center}
% 	\caption{\label{table:segmenter_architecture_table}Variantes de arquitectura de los modelos de segmentación de UDA.}
% \end{table}

% En la Figura \ref{fig:segmenter_model_loss} se observan las diferentes curvas de aprendizaje de los modelos 
% probados. Se muestra la rápida convergencia de los modelos con conexiones residuales y normalizaciones.
% Se muestra también la tendencia al sobreajuste en el entrenamiento entre los pasos 17-20, en donde se detiene el 
% entrenamiento para evitar el crecimiento del error de generalización.

% \begin{figure}[h]
% 	\centering
% 	\includegraphics[width=7cm,clip]{Graphics/persuasive_essays_all_linked_crf_loss.png}
% 	\caption{Pérdida de los modelos segmentadores.}
% 	\label{fig:segmenter_model_loss}
% \end{figure}

% Las métricas 100\%F1 y 50\%F1 muestran que los modelos 1 y 2 presentan un desempeño menor que los 3 y 4. 
% Se muestra un ligero aumento de 1\% en las 50\%F1 en el modelo 4 con respecto 
% al modelo 3, aunque las métricas de F1 en el 3 superan a las de 4. Se considera a la 
% segmentación como tarea principal, por lo que se selecciona como mejor modelo al 4 (Figura \ref{fig:test_segmenter_model_metrics}).
% Las distinciones BIOES en los nombres de tablas o métricas constituyen las métricas correspondientes 
% a la segmentación estrictamente, mientras las que no poseen dicha distinción constituyen al proceso 
% conjunto de segmentación y clasificación de UDAs. 

% \begin{figure}[h]
% 	\centering
% 	\includegraphics[width=7cm,clip]{Graphics/persuasive_essays_all_linked_components.png}
% 	\includegraphics[width=7cm,clip]{Graphics/persuasive_essays_all_linked_macro_micro_metrics.png}
% 	\caption{Métricas del conjunto de pruebas de los modelos segmentadores.}
% 	\label{fig:test_segmenter_model_metrics}
% \end{figure}

El modelo seleccionado fue usado en el entrenamiento de los demás conjuntos de datos obteniendo los resultados mostrados
en Tabla \ref{table:test_metrics_segmenter} y Tabla \ref{table:test_bioes_metrics_segmenter}.

Las métricas 50\%F1 y 100\%F1 se encuentran definidas en \cite{persing2016end}.
Métrica basada en la idea de F1 orientada para el trabajo con secuencias donde el número denota el porcentaje de secuencia inferida que debe coincidir con 
la secuencia anotada para ser considerado una coincidencia.

\begin{table}[h]
	\begin{center}
		\scalebox{0.7}{
		\begin{tabular}{|l|c|c|c|} 
			\hline\rule{-2pt}{15pt}
			{\bf Corpus}                 & {\bf Ensayos} 		& {\bf CDCP} & {\bf AbsTRCT} \\ 
						                 & {\bf Argumentativos} & 			 & 				 \\ 
			\hline\rule{-4pt}{10pt}
			F1 Ponderado 				 & 0,76         		& 0,65     	 & 0,86          \\
			Macro F1                     & 0,56         		& 0,45     	 & 0,50          \\
			\textit{Accuracy}            & 0,77         		& 0,66     	 & 0,87          \\ 
			100\%F1						 & 0,72         		& 0,61     	 & 0,61          \\ 
			50\%F1                		 & 0,83         		& 0,68     	 & 0,75          \\ 
			\hline
		\end{tabular}
		}
	\end{center}
	\caption{\label{table:test_metrics_segmenter}Métricas de las pruebas del segmentador de UDA.}
\end{table}
\begin{table}[h]
	\begin{center}
		\scalebox{0.7}{
		\begin{tabular}{|l|c|c|c|} 
			\hline\rule{-2pt}{15pt}
			{\bf Corpus}                 & {\bf Ensayos} 		& {\bf CDCP} & {\bf AbsTRCT} \\ 
						                 & {\bf Argumentativos} & 			 & 				 \\ 
			\hline\rule{-4pt}{10pt}
			F1 Ponderado 				 & 0,89         		& 0,95     	 & 0,90          \\
			Macro F1                     & 0,82         		& 0,56     	 & 0,79          \\
			\textit{Accuracy}            & 0,89         		& 0,96     	 & 0,91          \\ 
			100\%F1                		 & 0,81         		& 0,82     	 & 0,66          \\ 
			50\%F1                		 & 0,94         		& 0,93     	 & 0,82          \\ 
			\hline
		\end{tabular}
		}
	\end{center}
	\caption{\label{table:test_bioes_metrics_segmenter}Métricas BIOES de las pruebas del segmentador de UDA.}
\end{table}

En las tablas se observa una diferencia entre los valores de F1 Ponderado y 
de Macro F1, dadas por el pobre balance de las clases que hace que las menos
representadas sean más difíciles de ser correctamente anotadas. Los valores
mayores de 50\%F1 en comparación con 100\%F1 indican que el modelo logra 
inferir las posiciones de las UDA de manera general, pero sus límites se hacen 
más complejos de discernir. 

\subsection{Predictor de Enlaces}

Para el modelo se realizó un voto conjunto del ensamblado de tres modelos, dado que el entrenamiento 
está basado en la aleatoriedad, se entrenan los modelos con los mismos datos obteniendo inferencias no
necesariamente iguales.
% Para la selección del modelo se entrenaron diferentes variantes de arquitecturas e hiperparámetros, y 
% al igual que en el segmentador de UDAs se realizó la selección del modelo que mejor se desempeñó en 
% el conjunto de datos de Ensayos Argumentativos. De las variaciones surgieron las siguientes propuestas
% (Tabla \ref{table:link_predictor_architecture_table}):

% \begin{table}[h]
% 	\begin{center}
% 		\scalebox{0.9}{
% 		\begin{tabular}{|l|c|c|c|c|} 
% 			\hline\rule{-2pt}{15pt}
% 			{\bf Modelos}  		& {\bf 1}      & {\bf 2}  & {\bf 3} 	 & {\bf 4} 		\\ 
% 			\hline\rule{-4pt}{10pt}
% 			Atención 		    & $\times$     & $\times$ & $\checkmark$ & $\checkmark$ \\
% 			Pooling  		    & 5    		   & 10       & 1       	 & 1    		\\
% 			\textit{Dropout}    & 0,5   	   & 0,1      & 0,1       	 & 0,5	    	\\
% 			Tasa de 			&			   & 		  &		     	 & 		    	\\
% 			aprendizaje 		& 0,0015 	   & 0,003    & 0,003      	 & 0,0015    	\\
% 			Paciencia			& 10 		   & 5		  & 5       	 & 10		   	\\
% 			Devolver			&			   & 		  & 		  	 & 				\\
% 			mejores				& $\checkmark$ & $\times$ & $\times$  	 & $\checkmark$ \\
% 			\hline
% 		\end{tabular}
% 		}
% 	\end{center}
% 	\caption{\label{table:link_predictor_architecture_table}Variantes de arquitectura de los modelos de predicción de enlaces.}
% \end{table}

% Las curvas de aprendizaje del proceso de entrenamiento de los modelos (Figura \ref{fig:link_prediction_model_loss}) 
% muestran un nivel de sobreajuste 
% elevado que disminuyen cuando el \textit{dropout} aumenta. Además, se observan valores de pérdida elevados lo que significa 
% que al modelo le cuesta ajustarse de manera satisfactoria a los datos.

% \begin{figure}[h]
% 	\centering
% 	\includegraphics[width=7cm,clip]{Graphics/persuassive_essays_all_linked_link_prediction_loss_model_1.png}
% 	\caption{Curvas de aprendizaje de los modelos de predicción de enlaces.}
% 	\label{fig:link_prediction_model_loss}
% \end{figure}

% Las métricas obtenidas por las diferentes versiones de los modelos 
% (Figura \ref{fig:link_prediction_model_metrics}) 
% muestran que el modelo 2 constituye una opción ligeramente superior en lo correspondiente a 
% predicción de enlace a los otros modelos. Esos hiperparámetros
% fueron utilizados para el entrenamiento con los demás conjuntos de datos.

% \begin{figure}[h]
% 	\centering
% 	\includegraphics[width=7cm]{Graphics/persuasive_essays_all_linked_all_relation_f1_scores.png}\\
% 	\text{a)}\\
% 	\includegraphics[width=7cm]{Graphics/persuasive_essays_all_linked_all_relation_accuracy.png}\\
% 	\text{b)}\\
% 	\includegraphics[width=7cm]{Graphics/persuasive_essays_all_linked_all_relation_linked.png}\\
% 	\text{c)}
% 	\caption{Métricas F1 de la clasificación de enlace (a), \textit{accuracy} (b) y
% 		F1 de la predicción de enlace (c) de los modelos de predicción de enlaces.}
% 	\label{fig:link_prediction_model_metrics}
% \end{figure}

En el entrenamiento del modelo en los demás conjuntos de datos se obtuvieron los resultados de las Tablas 
\ref{table:test_relation_metrics_link_predictor_relation_classification} y 
\ref{table:test_relation_metrics_link_predictor_link_prediction}.
% y \ref{table:test_source_metrics_link_predictor}.

\begin{table}[h]
	\begin{center}
		\begin{tabular}{|l|c|c|} 
			\hline\rule{-2pt}{15pt}
			{\bf Corpus}                 & {\bf Macro F1} & {\bf \textit{Accuracy}} \\
			\hline\rule{-4pt}{10pt}
			Ensayos				 		 & 				  & 						\\ 
			argumentativos 		 		 & 0,33			  & 0,57					\\ 
			CDCP                   		 & 0,37			  & 0,63					\\ 
			AbsTRCT               		 & 0,39			  & 0,61					\\ 
			\hline
		\end{tabular}
	\end{center}
	\caption{\label{table:test_relation_metrics_link_predictor_relation_classification}Métricas de clasificación de relaciones de las pruebas del predictor de enlace.}
\end{table}

\begin{table}[h]
	\begin{center}
		\begin{tabular}{|l|c|c|} 
			\hline\rule{-2pt}{15pt}
			{\bf Corpus}                 & {\bf Macro F1}  & {\bf \textit{Accuracy}} \\
			\hline\rule{-4pt}{10pt}
			Ensayos 			 		 & 	               & 	                    \\ 
			argumentativos 				 & 0,68            & 0,75                   \\ 
			CDCP                   		 & 0,79            & 0,68                   \\ 
			AbsTRCT               		 & 0,83            & 0,74                   \\ 
			\hline
		\end{tabular}
	\end{center}
	\caption{\label{table:test_relation_metrics_link_predictor_link_prediction}Métricas de predicción de relaciones de las pruebas del predictor de enlace.}
\end{table}

En la Tabla \ref{table:test_relation_metrics_link_predictor_relation_classification} se observan
valores más discretos que en la Tabla \ref{table:test_relation_metrics_link_predictor_link_prediction}
en ambas métricas. Esta diferencia en la métrica Macro F1 se interpreta como el fallo del modelo 
en predecir correctamente la clase de la relación. En la tarea de predicción de 
enlace el modelo se desempeña mejor, aunque con diferencias entre los conjuntos de datos, 
dando a entender que la estructura de las relaciones de estos pueden influir en el resultado.

% \begin{table}[h]
% 	\begin{center}
% 		\begin{tabular}{|l|c|c|c|} 
% 			\hline\rule{-2pt}{15pt}
% 			{\bf Corpus}                 & {\bf F1 Macro} & {\bf \textit{Accuracy}} \\ 
% 			\hline\rule{-4pt}{10pt}
% 			Ensayos				   & 	      & 	            \\ 
% 			argumentativos		   & 0,48     & 0,60            \\ 
% 			CDCP                   & 0,26     & 0,52            \\ 
% 			AbsTRCT                & 0,51     & 0,79            \\ 
% 			\hline
% 		\end{tabular}
% 	\end{center}
% 	\caption{\label{table:test_source_metrics_link_predictor}Métricas de predicción de fuente de las pruebas del predictor de enlace.}
% \end{table}

% \begin{table}[h]
% 	\begin{center}
% 		\begin{tabular}{|l|c|c|c|} 
% 			\hline\rule{-2pt}{15pt}
% 			{\bf Corpus}           & {\bf Macro F1} & {\bf \textit{Accuracy}} \\ 
% 			\hline\rule{-4pt}{10pt}
% 			Ensayos				   & 	      & 	            \\
% 			argumentativos 		   & 0,52     & 0,57            \\
% 			CDCP                   & 0,36     & 0,54            \\
% 			AbsTRCT                & 0,53     & 0,81            \\ 
% 			\hline
% 		\end{tabular}
% 	\end{center}
% 	\caption{\label{table:test_target_metrics_link_predictor}Métricas de predicción de objetivo de las pruebas del predictor de enlace.}
% \end{table}

% \subsection{Acoplamiento de los modelos}

% Dado que la clasificación de UDAs es hecha tanto en el segmentador como en el predictor de enlaces, es necesaria 
% la selección de cómo se va a desambiguar esta clasificación. En caso de seleccionar el predictor de enlaces como 
% clasificador final, surgen varias cuestiones, como por ejemplo, que las UDAs pueden tomar varias clasificaciones o el
% predictor no toma el contexto del texto completo en la clasificación. Aunque la primera puede ser corregida
% mediante la selección de la clase más votada o algún otro criterio, la segunda presenta un mayor problema. Por
% esto es seleccionada la clasificación del segmentador como etiqueta final para las UDAs y el predictor es usado para 
% la tarea de extracción y clasificación de relaciones.

\section{Evaluación cualitativa de la EA}

Dado que las estructuras argumentativas varían en su forma en cada corpus es complejo realizar un método que evalúe de forma 
justa los resultados obtenidos por los diferentes modelos de manera conjunta. Una variante sería anotar las cartas 
con los esquemas argumentativos presentes en los conjuntos de datos, esto constituye una labor en la que se requiere
personal experto, previo estudio y preparación, además de tiempo. 

Por ello, el proceso que se llevó a cabo en esta investigación para realizar la 
validación consistió en un análisis cualitativo realizado a criterio del autor. Para esto se seleccionaron 15 pares 
de cartas, la carta original y la respuesta enviada a esta. Cada una de estas 30 cartas fueron anotadas por los modelos entrenados en cada 
conjunto de datos y se realizó una evaluación que consideró si la UDA se extrajo y clasificó correctamente, 
así como si la relación también fue extraída y clasificada por el modelo de manera adecuada:

% \begin{itemize}
% 	\item Muchos falsos positivos en la predicción de enlaces, debido a la manera en la manera componente a componente que 
% 	se hacen
% 	\item En los textos en donde la segmentación es por oraciones, los puntos relacionados a otra acción que 
% 	no sea separar oraciones son seleccionados como separadores.
% 	\item La segmentación, se queda corta o larga?
% \end{itemize}

\subsection{Análisis del corpus Ensayos Argumentativos}

% \begin{figure}[h!]
% 	\begin{center}
% 		\includegraphics[scale=.4]{Graphics/persuasive_2019-01-25_informa-recursos-hidraulicos-sobre-abasto-de-agua-en-manzanillo_abasto-de-agua-en-manzanillo.png}
% 		\includegraphics[scale=.4]{Graphics/persuasive_2019-03-22_inconformidad-con-la-chequera.png}
% 	    \caption{A}\label{fig:persuasive_granma_letters}
% 	\end{center}
% \end{figure}

Los ensayos argumentativos presentan una anotación de UDAs a un nivel de unidades de texto que pueden ser 
más pequeñas que oraciones y clasifican estas en las clases \textit{MajorClaim} (MC), \textit{Claim} (C) y \textit{Premise}
(P). Las relaciones se clasifican en de \textit{supports} y \textit{attacks}. 

En general, se observan problemas en la segmentación de UDAs debido al formato y dominio del texto.
Las cartas presentan una estrutura donde al final se realiza una firma poniendo información acerca del remitente.
Esta estructura no contribuye a la argumentación, pero el modelo en varias ocasiones detecta componentes en estas. 
Otro problema se observa en la extracción de supuestas UDAs sin componente argumentativo,
generalmente, estos elementos, si se expanden, pueden lograr establecer una mejor UDA.

Ejemplos donde el modelo propuesto no fue exitoso:
\begin{itemize}
	% \item \text{} [años de explotación y]$_{MC}$
	%       : muy corto y no informativo. % 2019-01-25_informa-recursos-hidraulicos-sobre-abasto-de-agua-en-manzanillo_abasto-de-agua-en-manzanillo.txt.conll.link.conll.ann
	\item \text{} [en cada uno de los establecimientos de nuestra Cadena de Tiendas]$_{MC}$
	      : incompleto, mejora incorporando elementos de la izquierda (No a todos los productos con próxima fecha de vencimiento se le aplica rebaja de precios). % 2018-12-07_responde-trd-caribe-al-consumidor_a-proposito-de-la-proteccion-al-consumidor.txt.conll.link.conll.ann
	% \item \text{} [Director División Grandes Centros]$_{MC}$ [TRD Caribe]$_{C}$
	%       : mala clasificación y segmentación. %  2018-12-07_responde-trd-caribe-al-consumidor_a-proposito-de-la-proteccion-al-consumidor.txt.conll.link.conll.ann
	\item \text{} [Esperamos lo antes posible una solución]$_{P}$
	      : en contexto, no contiene información que lo haga premisa. % 2018-10-05_abasto-de-agua-en-manzanillo.txt.conll.link.conll.ann
	% \item \text{} [no podemos permitir]$_{C}$
	%       : no establece una \textit{claim}. % 2017-06-30_inass-reconoce-razon-de-ramiro-castellanos-por-inconformidad-con-trato-de-especialista-de-las-tunas_pregunta-quien-le-paga-su-jubilacion.txt.conll.link.conll.ann
\end{itemize}

Ejemplos donde el modelo fue exitoso:
\begin{itemize}
	% \item \text{} [no se le puede volver a despachar, tiene que ver a la administración (si está ahí en ese momento),
	% 	      si no, regresar al día siguiente para que se le acredite lo sucedido]$_{MC}$ % 2021-02-26_inconvenientes-con-tarjetas-de-combustible-en-moneda-nacional.txt.conll.link.conll.ann
	% \item \text{} [administración de la EMI Yuri Gagarin desde inicios de la confección del expediente para
	% 	      mi jubilación, no contempló el salario obtenido por pluriempleo]$_{MC}$ % 2019-03-22_inconformidad-con-la-chequera.txt.conll.link.conll.ann
	\item pudiese [contribuir al ahorro de agua y la prestación de un mejor servicio]$_C$ % 2018-10-05_abasto-de-agua-en-manzanillo.txt.conll.link.conll.ann
	\item \text{} [es que estamos limitados de este servicio, y no desde hace un tiempo, es que nunca lo hemos tenido]$_P$ % 2018-05-18_sin-cobertura-en-guara-mayabeque.txt.conll.link.conll.ann
	% \item \text{} [el número de carné de identidad que se encontraba en dicha base de datos correspondía a otra persona que
	% 	      fue reportada como fallecida]$_P$ % 2017-06-30_inass-reconoce-razon-de-ramiro-castellanos-por-inconformidad-con-trato-de-especialista-de-las-tunas_pregunta-quien-le-paga-su-jubilacion.txt.conll.link.conll.ann
\end{itemize}

Las relaciones anotadas por el modelo tienden a contener falsos positivos, además
dado que este conjunto de datos posee un gran desbalance en las etiquetas de las relaciones favoreciendo 
estas a las de \textit{supports}, el modelo no fue capaz de realizar anotaciones de \textit{attacks}, tanto en 
el conjunto de pruebas como en las ``Cartas a la Dirección'' del \textit{Granma}.

\subsection{Análisis de CDCP}

% \begin{figure}[h!]
% 	\begin{center}
% 		\includegraphics[scale=.4]{Graphics/cdcp_2019-01-25_informa-recursos-hidraulicos-sobre-abasto-de-agua-en-manzanillo_abasto-de-agua-en-manzanillo.png}
% 		\includegraphics[scale=.4]{Graphics/cdcp_2019-03-22_inconformidad-con-la-chequera.png}
% 	    \caption{A}\label{fig:cdcp_granma_letters}
% 	\end{center}
% \end{figure}

El corpus CDCP las UDAs son segmentadas, en la mayoría de los casos, en oraciones 
(solamente el 1\% de los \textit{tokens} se encuentran fuera de una UDA),
estas son clasificadas en \textit{testimony} (T), \textit{fact} (F), \textit{policy} (P), \textit{reference} (R)
y \textit{value} (V). Las relaciones presentan dos tipos de relaciones \textit{evidences} y \textit{reasons}.

Los errores más comunes cometidos por el modelo propuesto en la segmentación, provienen del uso 
de signos de puntuación que no representan un cambio de oración, en estos casos se separan las UDAs. También
existen errores de clasificación incorrecta, de, por ejemplo, \textit{testimony} que podrían ser \textit{fact}.

Ejemplos deonde el modelo propuesto no fue exitoso:
\begin{itemize}
	% \item \text{} [\dots Bayamo, km 1 No.]$_T$ [30 A (interior), \dots]$_T$
	%       : uso del \textbf{.} para abreviar número se toma como separador de UDA. % 2019-01-25_informa-recursos-hidraulicos-sobre-abasto-de-agua-en-manzanillo_abasto-de-agua-en-manzanillo.txt.conll.link.conll.ann
	% \item \text{} [\dots ,desde el 1ro.]$_T$ [de marzo \dots]$_T$
	%       : Uso del \textbf{.} para abreviar primero se toma como separador de UDA. % 2019-05-24_le-retribuyen-la-diferencia-reclamada-de-su-pension_inconformidad-con-la-chequera.txt.conll.link.conll.ann
	\item \text{} [Junto a la misiva se le entregó al Inass certificados de salarios devengados y las tarjetas sn2-25.]$_T$
	      : se clasifica mejor como \textit{fact}. % 2019-03-22_inconformidad-con-la-chequera.txt.conll.link.conll.ann
	\item \text{} [Caridad Real Gutiérrez, Jefe de Trámites y Pensiones, Inass.]$_T$
	      : firma de la carta como elemento argumentaivo. % 2019-05-24_le-retribuyen-la-diferencia-reclamada-de-su-pension_inconformidad-con-la-chequera.txt.conll.link.conll.ann
\end{itemize}

Ejemplos donde el modelo propuesto fue exitoso:
\begin{itemize}
	% \item \text{} [En el 2017 se colocaron tuberías de 200, 160 y 110 mm, quedando no concluido y de
	% 	      continuidad para el 2018 se situó un financiamiento para construcción de registros y colocación de 
	% 	      válvulas y ventosas.]$_F$ % 2019-01-25_informa-recursos-hidraulicos-sobre-abasto-de-agua-en-manzanillo_abasto-de-agua-en-manzanillo.txt.conll.link.conll.ann
	\item \text{} [Mi jubilación comenzó el 29 de febrero de 2016, no el 29 de febrero de 2017.]$_T$ % 2019-03-22_inconformidad-con-la-chequera.txt.conll.link.conll.ann
	\item \text{} [No se sabe cuánto queda, lo que obliga al cliente a estar haciendo cuentas constantemente.]$_F$ % 2021-05-07_servicentros-operan-diversos-medios-de-pago-electronicos_inconvenientes-con-tarjetas-de-combustible-en-moneda-nacional.txt.conll.link.conll.ann
\end{itemize}

La cantidad de relaciones anotadas por el modelo entrenado en este corpus
disminuye en comparación a las anotadas por el modelo entrenado con el corpus Ensayos
Argumentativos. Las relaciones \textit{reasons} son las más encontradas. % TODO Poner numeros de esto

% Las relaciones presentes disminuyen en cantidad en comparación con lo visto en los textos anotados con el modelo 
% entrenado con Ensayos Argumentativos. Prevaleciendo las relaciones de \textit{reasons}. A consideración del autor,
% la cantidad de los falsos positivos son menores que cuando se utilizó el modelo entrenado con el corpus Ensayos Argumentativos.

\subsection{Análisis del corpus AbsTRCT}

% \begin{figure}[h!]
% 	\begin{center}
% 		\includegraphics[scale=.4]{Graphics/abstrct_2019-01-25_informa-recursos-hidraulicos-sobre-abasto-de-agua-en-manzanillo_abasto-de-agua-en-manzanillo.png}
% 		\includegraphics[scale=.4]{Graphics/abstrct_2019-03-22_inconformidad-con-la-chequera.png}
% 		\caption{A}\label{fig:abstrct_granma_letters}
% 	\end{center}
% \end{figure}

El conjunto de datos presenta un estilo de segmentación de UDAs en donde se anotan 
secciones de textos más grandes que en el corpus Ensayos Argumentativos, aunque no necesariamente 
todas las oraciones o la oración completa es considerada argumentativa. 
Estas se clasifican igual que el corpus Ensayos Argumentativos, aunque 
en este conjunto de datos se presenta un desbalance de etiquetas grande, favoreciendo 
a las \textit{Premise} y las \textit{Claim}, % TODO Poner porcientos
dejando sin representación casi a \textit{MajorClaim}
(menor del 1\% de las etiquetas BIOES), lo que trajo como consecuencia que el modelo no fuera 
capaz de diferenciar este tipo de UDA. Las relaciones se presentaron como \textit{partial-attack},
\textit{attack} y \textit{support}, influenciadas también por la poca cantidad de relaciones de \textit{attack}.

En la clasificación de UDAs se evidencia una gran cantidad de \textit{Premise}.

Ejemplos deonde el modelo propuesto no fue exitoso:
\begin{itemize}
	% \item \text{} [\dots Calle 14, apto.]$_P$ [4 entre Zapata y 23, \dots]$_T$
	%       : uso del \textbf{.} para abreviar la palabra apartamento, que se toma como separador de UDA. % 2017-07-07_parque-en-pleno-deterioro-en-plaza.txt.conll.link.conll.ann
	\item \text{} [, Director División Grandes Centros TRD Caribe.]$_C$
	      : mala clasificación con mala segmentación y detección de \textit{claim} en pie de firma de la carta. 
\end{itemize}

Ejemplos donde el modelo propuesto fue exitoso:
\begin{itemize}
	% \item \text{} [Esta situación pudo haberse evitado y no podemos permitir que hechos como este ocurran pues,
	% 	      empañan la imagen de la institución que está destinada a brindar un servicio con calidad a la población en 
	% 	      general y en especial a los jubilados y pensionados.]$_P$ % 2017-06-30_inass-reconoce-razon-de-ramiro-castellanos-por-inconformidad-con-trato-de-especialista-de-las-tunas_pregunta-quien-le-paga-su-jubilacion.txt.conll.link.conll.ann
	\item \text{} [Esta respuesta considera sin razón la preocupación de un lector,
		      ¿así debe terminar la inquietud de un ciudadano, que confía en las instituciones con que cuenta la 
		      sociedad para enfrentar sus problemas?]$_C$ % 2017-05-12_cimex-se-dirige-a-limitado-fisico-motor_llamado-a-evaluar-situacion-de-piezas-y-baterias-para-equipos-motorizados-de-discapacitados.txt.conll.link.conll.ann
\end{itemize}

La cantidad de relaciones anotadas por el modelo entrenado en este corpus es la menor
de los demás conjuntos de datos. Se observa una gran cantidad de relaciones \textit{support}. % TODO Poner numeros de esto
Las relaciones clasificadas como \textit{partial-attack}, a consideración del autor, presentaron 
una baja precisión.

% Las relaciones tienen la menor cantidad de elementos de los otros conjuntos de datos, proliferando
% las relaciones de \textit{support}. En las clasificadas como \textit{partial-attack} se evidenció, a 
% consideración del autor, una baja precisión. 
% Por ejemplo 
% 	[\textit{cierto que la responsabilidad es de todos, pero la institucional es de la Dirección de Comunales.}]
% ataca a [\textit{Antonio Blanco, Director de Servicios Comunales Plaza,}].

\section{Discusión}

% \subsection{Comparación con el estado del arte}

Las comparaciones con el estado del arte se realizan por cada conjunto de datos y se muestran las 
métricas indicadas por los autores de cada propuesta. Cada corpus y propuesta 
presenta características únicas que hacen que difícil la comparación. 

Una de las principales dificultades está dada por el hecho de que las métricas calculadas son de la versión proyectada
al español, lo cual contribuye a variaciones en las etiquetas finales debido al lenguaje mismo 
o a errores en el proceso. Otros ejemplos en la dificultad de comparar las métricas se encuentra
en los enfoques tomados por las investigaciones anteriores a la hora de realizar las tareas.
En algunos casos la segmentación se presenta como una tarea de clasificación BIO, o
se separan por oraciones y las clasifican en argumentativas o no.

En el aspecto de clasificación
de las UDAs se emplean métodos como su clasificación independiente luego de ser extraída o su modelación
conjunta con la segmentación. En la extracción y clasificación de relaciones se observan técnicas de 
optimización de problemas enteros, clasificación por SVM o también probando los posibles enlaces dos 
a dos independientemente.

En la comparación de métodos se seleccionaron seis métricas que evalúan las diferentes 
tareas de la EA. La métrica BIOES F1 se refiere 
a la Macro F1 de la clasificación de las etiquetas BIOES, esta constituye una medida
que califica la tarea de segmentación de UDAs en el texto. 

La métrica Clas UDA F1 es 
calculada como la Macro F1 de las etiquetas BIOES junto con las etiquetas del tipo de 
UDA, medida que evalúa la tarea de clasificación de las UDAs. 

Rel Pred F1 es la medida 
Macro F1 de la predicción de enlaces y Rel Clas F1 la de la clasificación, estas 
son calculadas tomando en cuenta todos los pares seleccionados para el conjunto de 
datos. 

En las Tablas \ref{table:comparative_test_essays_f1_metrics_segmenter}-\ref{table:comparative_test_abstrct_f1_metrics_segmenter} el símbolo $\checkmark$ significa 
que los algoritmos son directamente comparables, el símbolo
$*$ expresa que el método de comparación es el mismo, pero no son usados los mismos 
elementos para calcular la métrica, y el símbolo $\times$ denota que la métrica no 
se computó en las investigaciones donde se propusieron los modelos.

\begin{table}[h]
	\begin{center}
		\scalebox{0.65}{
		\begin{tabular}{|p{30mm}|c|c|c|c|} 
			\hline\rule{-2pt}{15pt}
			{\bf Modelo}      				& {\bf BIOES} 			 & {\bf Clas} 	& {\bf Rel} 	& {\bf Rel} 	\\ 
						      				& {\bf F1} 				 & {\bf UDA F1} & {\bf Pred F1} & {\bf Clas F1} \\ 
			\hline\rule{-4pt}{10pt}
			Propuesto    					& 0,82     				 & 0,56      	& 0,68          & 0,33              \\
			\namecite{stab2017parsing} 		& 0,85  $\checkmark$     & 0,82      	& 0,58          & 0,70              \\
			\namecite{niculae2017argument}  & $\times$   			 & 0,77      	& 0,60          & $\times$          \\
			\namecite{galassi2021deep}      & $\times$  			 & 0,53      	& 0,36 *        & 0,18 *            \\ 
			\hline
		\end{tabular}
		}
		\caption{\label{table:comparative_test_essays_f1_metrics_segmenter}Métricas comparativas del corpus Ensayos Persuasivos.}
	\end{center}
\end{table}
\begin{table}[h]
	\begin{center}
		\scalebox{0.65}{
		\begin{tabular}{|p{30mm}|c|c|c|c|} 
			\hline\rule{-2pt}{15pt}
			{\bf Modelo}      				& {\bf BIOES} 			 & {\bf Clas} 	& {\bf Rel} 	& {\bf Rel} 	\\ 
						      				& {\bf F1} 				 & {\bf UDA F1} & {\bf Pred F1} & {\bf Clas F1} \\ 
			\hline\rule{-4pt}{10pt}
			Propuesto    				& 0,56      	 & 0,45         	 & 0,68 			 & 0,37               \\
			\cite{niculae2017argument}  & $\times$       & 0,73              & 0,27 			 &  $\times$          \\
			\cite{galassi2021deep} 		& $\times$  	 & 0,79              & 0,30	*   		 &  0,15	*         \\
			\hline
		\end{tabular}
		}
		\caption{\label{table:comparative_test_cdcp_f1_metrics_segmenter}Métricas comparativas del corpus CDCP.}
	\end{center}
\end{table}
\begin{table}[h]
	\begin{center}
		\scalebox{0.65}{
		\begin{tabular}{|p{30mm}|c|c|c|c|} 
			\hline\rule{-2pt}{15pt}
			{\bf Modelo}      				& {\bf BIOES} 			 & {\bf Clas} 	& {\bf Rel} 	& {\bf Rel} 	\\ 
												& {\bf F1} 				 & {\bf UDA F1} & {\bf Pred F1} & {\bf Clas F1} \\ 
			\hline\rule{-4pt}{10pt}
			Propuesto    				& 0,79      	 & 0,50              & 0,74 			 & 0,39               \\
			\cite{mayer2020transformer} & $\times$       & 0,88	$\checkmark$ & $\times$  		 & 0,66 *             \\
			\cite{galassi2021deep} 		& $\times$  	 & 0,91 	         & 0,54 *            & 0,70 *    		  \\
			\hline
		\end{tabular}
		}
		\caption{\label{table:comparative_test_abstrct_f1_metrics_segmenter}Métricas comparativas del corpus AbsTRCT.}
	\end{center}
\end{table}

% \subsection{Análisis de los conjuntos de datos}

por otra parte, se considera que el corpus CDCP se ajusta mejor a las características de las ``Cartas 
a la Dirección''. Este presenta orígenes similares y un conjunto de etiquetas de UDAs que se ajustan más a lo observado 
en las Cartas. También las Cartas presentan un alto contenido argumentativo, por lo que marcar 
todas las oraciones como argumentativas no constituye una fuente grande de errores.
% , aunque esta parte puede ser mejorada

Una desventaja de este esquema sobre otros es la carencia de una 
clasificación de las relaciones que implique un ataque, aunque esto se cubre con el hecho de 
que en los conjuntos en donde existen estas, los resultados son bastante pobres en ese aspecto. La cantidad 
y calidad de relaciones, aunque tiene bastante espacio para mejorar, es aceptable dada la dificultad 
del problema en EA.

La ventaja del modelo entrenado con el corpus de Ensayos Argumentativos en la extracción 
y clasificación de UDA es que utiliza un conjunto de etiquetas que 
podría considerarse universal en la argumentación y además reduce el espacio de búsqueda de 
oraciones a segmentos de palabras, aunque estos puedan estar sujetos a errores. 

La versión del modelo propuesto entrenado sobre el corpus AbsTRCT constituye el modelo 
con menor rendimiento. La clasificación
de UDAs presentó una gran desproporción hacia \textit{Premise} dejando muchas \textit{Claim} % TODO Poner numeros
sin ser correctamente clasificadas. Sobre las relaciones, reportó un nivel muy bajo de 
relaciones por documento, respecto a las que se podrían formar.

\section{Conclusiones}

En la investigación se logró la extracción de estructuras argumentativas en los textos de las 
``Cartas a la Dirección'' del periódico \textit{Granma}. Para esto se hizo un análisis de los
modelos entrenado con los distintos conjuntos de datos y se seleccionó el modelo que más se ajustaba
al dominio de las cartas. Esta
selección se realizó sin tener un conjunto anotado por lingüistas de las Cartas,
por lo que los autores fueron los que establecieron los criterios cualitativos 
para la selección del modelo final.

En los resultados obtenidos en las tareas de segmentación y clasificación de UDAs se observan
valores 50\%F1 entre 0,82 y 0,94 y 0,68 y 0,83, respectivamente, indicando una segmentación aceptable 
pero que en ocasiones falla a la hora de clasificar correctamente. Al predecir los enlaces y clasificarlos 
los modelos obtienen resultados de Macro F1 entre 0,68 y 0,83 y 0,33 y 0,39, respectivamente. Estos evidencian
una mayor dificultad a la hora de trabajar con las relaciones, sobre todo al clasificarlas. 
Las comparaciones con las investigaciones previas con los resultados de los modelos entrenados 
se vieron dificultadas por los diferentes enfoques presentados en estas a la hora de seleccionar 
cómo modelar el problema y cómo procesar los datos para entrenar los modelos.

Este trabajo aportó nuevos conjuntos de datos, estos son las ``Cartas a la Dirección'' extraídas del \textit{Granma},
los corpus proyectados al español de Ensayos Argumentativos, AbsTRCT y CDCP y las Cartas 
anotadas con las estructuras argumentativas del modelo entrenado con el conjunto de datos CDCP. También
presentó unos modelos capaces de adaptarse a los diferentes esquemas que se puedan presentar en la argumentación,
haciéndolos viables para un estudio directo y sin el agrego de conocimiento específico de los datos.
% , evidenciado en el análisis hecho con tres conjuntos de datos independientes.

% En el trabajo se logró la extracción de estructuras argumentativas en los textos de las 
% ``Cartas a la Dirección'' del periódico \textit{Granma}. Para esto se 
% extrajeron los textos de las Cartas creando un conjunto de datos con estos y también
% se obtuvo las versiones proyectadas al español de Ensayos Argumentativos, AbsTRCT y CDCP.
% conteniendo, no solo el texto de las cartas, si no, los comentarios 
% escritos por los usuarios e información sobre la carta a la que responde, si es una respuesta.
% Se creó un software\footnote{\url{https://github.com/luisoibarra/argument-mining}} que puede 
% ser utilizado no solo para el trabajo con las Cartas a la Dirección, si no
% que este permite un uso general para las tareas de proyección de corpus y trabajo relacionados a la EA.
% Este permite incorporar nuevas componentes haciendo posible una extensión simple y desacoplada. 
% Los modelos creados, uno encargado 
% de la segmentación y clasificación de las UDAs, y otro de la extracción y clasificación de las 
% relaciones entre estas, fueron utilizados para la anotación de los textos extraídos. Estos modelos
% permiten el análisis de diferentes esquemas de anotación en los conjuntos de datos debido a su 
% Los resultados obtenidos en la tarea de segmentación se encuentran al nivel del estado del arte,
% en las demás tareas no se encontraron comparaciones directas al enfoque tomado en la propuesta,
% aunque no teniendo en cuenta esto, se obtienen comparativas inferiores en la clasificación
% de UDAs y en la clasificación de relaciones, aunque se supera la métrica de predicción de enlace. 
% Los resultados obtenidos del procesamiento de las ``Cartas a la Dirección'' son considerados 
% aceptables por autor.

El software implementado y los datos pueden encontrarse en \url{https://github.com/luisoibarra/argument-mining}.

\section{Recomendaciones}

La principal dificultad en el trabajo fue la carencia de un conjunto de anotados
sobre el tema en específico relacionado con la extracción de argumentos en la prensa.
Por lo que se propone la creación de un corpus anotado por lingüistas para poder realizar una mejor 
validación y entrenamiento del modelo propuesto. También se considera la creación de un servicio 
online basado en Brat\footnote{\url{https://brat.nlplab.org/}} para la socialización y mejora de 
los resultados obtenidos.
El uso de representaciones BERT ha llevado a muchas tareas de PLN a nuevos estados 
del arte, por lo tanto, se propone investigar el uso de estos \textit{embeddings} en 
el modelo. El problema principal obtenido en el modelo fue relacionado con la 
predicción de enlaces, un problema que tiene el modelo es la falta de contexto global
del texto para hacer la predicción, por lo que se insta a la búsqueda y experimentación
de métodos que tomen esto en cuenta, una variante podrían ser las \textit{Graph Neural Networks} \cite{wu2021comprehensive}.

\section*{Agradecimientos}

Los autores agradecen el apoyo del Proyecto de Investigación 
``Dinámicas sociales, políticas y económicas en el discurso público 
en Cuba de principio del siglo XXI: estudios de CORESPUC'', 
asociado al Programa Nacional de Ciencia y Técnica ``Las Ciencias Sociales y las Humanidades. 
Desafíos ante la estrategia de desarrollo de la sociedad cubana'', Código PN223LH011-011, Ministerio
de Ciencia, Tecnología y Medio Ambiente (CITMA), Cuba, 2021-2023.

\bibliographystyle{fullname_esp}
\bibliography{EjemploARTsepln}

\end{document}
